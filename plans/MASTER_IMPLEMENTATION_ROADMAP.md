# Master Implementation Roadmap
## AI Alignment Game Theory Simulation

**Date:** October 17, 2025
**Purpose:** Active work items only - completed work in `/plans/completed/`
**Philosophy:** Research-backed realism, mechanism-driven emergence

**‚ö†Ô∏è NOTE ON ESTIMATES:** Hour estimates in this document are historical records of AI agent completion times. For new work, use **complexity** instead (number of interacting systems). AI agents complete work in minutes, not hours - e.g., "Complexity: 5 systems" (environmental, social, AI, economy, governance).

---

## Research-Backed Realism

> "We are never going for specific outcomes, only trying to figure out the most realistic, defensible model we can - let the model show what it shows."

**Guiding Principles:**
1. **Research First:** Every mechanic backed by 2024-2025 peer-reviewed research
2. **Mechanisms Over Balance:** Set parameters to real-world values, don't tune for "fun"
3. **Emergence:** Allow unexpected outcomes to emerge from interactions
4. **Documentation:** Every system has research citations

**Recent Research Additions (Oct 16, 2025):**
- Katz & Krueger (2019): Retraining effectiveness by socioeconomic status
- Harvey (2005) & MGNREGA (2020): Job guarantee program quality stratification
- Chetty et al. (2014): Educational access and outcomes by socioeconomic background
- Kahneman & Deaton (2010): Income-life satisfaction relationship
- Alaska PFD: Universal basic income wage gap reduction
- Acemoglu (2024): Displacement without reinstatement framework
- Sen (1999): Capabilities approach (freedom > outcomes if basic needs met)
- Frase (2016): Four Futures framework (Rentism, Exterminism scenarios)

---

## Current State Summary

### ‚úÖ Completed & Archived

**TIER 0 (ALL COMPLETE):** Critical bug fixes - inconclusive outcomes, orphaned AIs, compute paradox, policy validation (10-18h)
**TIER 1 (Phase 1A-1C COMPLETE):** Nuclear war prevention - Bayesian risk redesign, circuit breakers, validation (18-26h)
  - Phase 1D DEFERRED (not needed - 0% nuclear war rate achieved)
**Contingency & Agency Phase 1 (COMPLETE):** L√©vy flights - fat-tailed distributions (2-4h)
**TIER 0-3:** Baseline corrections, extinction risks, crisis mitigations, planetary boundaries
**TIER 4.1-4.5:** Tech tree (70 techs), dystopia paths, info warfare, energy/resources, population
**Priority 0 (P0):** 7 critical fixes - AI growth, bankruptcy, determinism, stochasticity (‚úÖ 7/7 complete)
**Priority 1 (P1):** 5 high-priority fixes - death accounting, mortality rates, recovery mechanics (‚úÖ 5/5 complete)
**Priority 2 (P2):** 6 medium improvements - environmental calibration, breakthroughs, org diversification, heterogeneous populations, simulation features, memetic evolution (‚úÖ 6/6 complete)

**Recent Completions (Oct 16-17, 2025):**
- ‚úÖ TIER 0A-0D: Critical bug fixes validated (10-18h)
- ‚úÖ TIER 1 Phase 1A: Bayesian nuclear risk redesign (8-10h)
- ‚úÖ TIER 1 Phase 1B: Nuclear command control circuit breakers (8-12h)
- ‚úÖ TIER 1 Phase 1C: Validation gate passed (2-4h)
- ‚úÖ Contingency & Agency Phase 1A: L√©vy flights initial implementation (2-4h)
- ‚úÖ Contingency & Agency Phase 1B: L√©vy flights recalibration (4-6h) - 30-36% utopia achieved
- ‚úÖ Contingency & Agency Phase 1B Hybrid Refinement: ALL 5 TASKS COMPLETE (12-15h) - Humane vs pyrrhic outcomes, famine fixes, trauma modeling, mortality-stratified reporting
- ‚úÖ Contingency & Agency Phase 2: Exogenous shocks (8-12h) - COMPLETE & VALIDATED N=100
  - Black swans: 0.1%/month (PERFECT MATCH to research)
  - Gray swans: 0.825%/month (82.5% of expected, within variance)
  - 8% of runs affected (target: 5-10%)
  - 8 shock types validated (nuclear, pandemic, asteroid, AGI, tech, finance, political, regional war)
  - 4 critical bugs fixed during validation
- ‚úÖ Policy Calibration Improvements: All 4 phases complete (6-10h) - UBI bug fixed

**All details:** See `/plans/completed/` directory

---

### Medium Priority Features (~31-38 hours)

**New Outcome Spaces:**

- [x] **TIER 4.6: Human Enhancement & Merger Pathways** ‚ö†Ô∏è IMPLEMENTED BUT NEEDS RECONCILIATION (8h actual)
  **Status:** Added humanEnhancement.ts system with segment-level tracking, BUT overlaps with existing bionicSkills.ts
  ‚Üí BCI/merger pathways: Research skeptic correct (TRL 0-2, science fiction) - should be removed
  ‚Üí AI-assisted cognition: Already exists in `bionicSkills.ts` (TRL 8-9) - need to reconcile duplication
  ‚Üí See: `plans/tier4-6-human-enhancement.md` + `devlogs/crisis_accumulation_fixes_oct16_2025.md`
  ‚Üí Next: Merge humanEnhancement.ts segment tracking into bionicSkills.ts, remove BCI/merger

**Research-Backed Enhancements:**

- [ ] **Digital Consciousness Governance Preparedness** (12-16h) **[Black Mirror Phase 3]** üîí **IN PROGRESS (Oct 17)**
  Multi-scenario rights timeline modeling (15-200 years), regional governance variation (EU/US/China/Global South), rights reversal mechanics (Poland/Hungary model), precautionary principle costs
  ‚Üí See: `plans/digital-consciousness-governance-preparedness.md`
  ‚Üí Research: TRL 3-4 (historical data validated, AI extrapolation speculative), 22 sources
  ‚Üí Status: CONDITIONAL GO (October 16, 2025) - requires multi-scenario, regional variation, rights reversals, precautionary costs
  ‚Üí Impact: Governance layer for potential digital consciousness emergence (scenario generator, not prediction)
  ‚Üí **ASSIGNED:** Feature implementer (started Oct 17, 2025)

---

---

## Contingency & Agency Modeling - HIGH PRIORITY (20-30 hours remaining, phased)

**Date Added:** October 17, 2025
**Source:** Modeling contingency and agency debate (research-skeptic + super-alignment-researcher consensus)
**Evidence:** Monte Carlo seed convergence analysis revealing deterministic outcomes
**Status:** Phase 1 COMPLETE ‚úÖ, Phase 2 COMPLETE ‚úÖ, Phase 1B Hybrid Refinement COMPLETE ‚úÖ - Phase 3 PENDING
**Prerequisites:** TIER 0D validated (ensure model stability before adding variance)

**Research Foundation:**
- Clauset et al. (2009): Power-law distributions in empirical data (natural/social systems follow fat tails, not Gaussian)
- Bak et al. (1987): Self-organized criticality (systems evolve to critical states where minor events trigger avalanches)
- Sornette (2003): Critical phase transitions in social sciences (crashes/revolutions show power-law signatures)
- Mantegna & Stanley (1994): Financial returns follow L√©vy stable distributions
- Svolik (2012): Autocratic critical junctures (elite coordination problems create windows for agency)
- Kuran (1991): Preference falsification cascades (one defector reveals hidden opposition ‚Üí cascade)
- Sen (1999): Development as Freedom (democracies + info + institutions enable agency)
- Acemoglu et al. (2001): Institutions determine outcomes across centuries (structure usually dominates)

**Core Problem:** Current simulation shows 80-90% seed convergence (same outcomes, only timing varies). This indicates **deterministic attractors** rather than genuine unpredictability. Real history has **fat-tailed events** (black swans), **path contingency** (small differences compound), and **individual agency at critical junctures** (Arkhipov, Borlaug, Montreal Protocol).

**Phased Implementation with Validation Gates:**

### Phase 1B Hybrid Refinement - Research Debate Consensus (12-15h) - ‚úÖ COMPLETE (Oct 17)

- [x] **Phase 1B Hybrid Refinement** (12-15h actual) - **COMPLETE**
  ‚Üí **Status:** ALL 5 TASKS COMPLETE - Validation N=100 running
  ‚Üí **Context:** Phase 1B achieved 30-36% utopia (from 0%), revealed conceptual issues
  ‚Üí **Key Finding:** "Utopia" included runs with 84% mortality (6.7B deaths) - now stratified

  **5 Priority Refinements - ALL COMPLETE:**

  1. ‚úÖ **Famine System Fixes (2-3h)** - COMPLETE
     - Fixed: Lowered threshold 0.4 ‚Üí 0.6, added crisis multiplier, infrastructure collapse
     - Root cause identified: Food security recalculated from scratch (architectural issue)
     - Files: qualityOfLife.ts, planetaryBoundaries.ts, FoodSecurityDegradationPhase.ts

  2. ‚úÖ **Humane vs Pyrrhic Utopia Classification (3-4h)** - COMPLETE
     - Implemented: Stratified outcomes by mortality bands (<20%, 20-50%, 50-75%, >75%)
     - New categories: Humane Utopia, Pyrrhic Utopia, Humane Dystopia, Pyrrhic Dystopia, Bottleneck
     - Critical bug fixed: Mortality calculation shared reference issue
     - Files: game.ts, engine.ts, monteCarloSimulation.ts

  3. ‚úÖ **Psychological Trauma Modeling (3-4h)** - COMPLETE
     - Implemented: PsychologicalTraumaPhase at order 23.5
     - Mechanism: Triggers on >10% monthly mortality, recovers -0.02/month
     - QoL impact: Non-linear penalty (power 1.5) reduces mental health, social, trust
     - Research: Wilkinson & Pickett (2009), PTSD literature, Diamond (2005)
     - Files: PsychologicalTraumaPhase.ts, game.ts, initialization.ts, qualityOfLife.ts

  4. ‚úÖ **Mortality-Stratified Reporting (2h)** - COMPLETE
     - Integrated with stratified outcome classification
     - Reports outcomes by mortality bands with humane vs pyrrhic breakdown
     - Files: monteCarloSimulation.ts

  5. ‚úÖ **Famine Investigation (2h)** - COMPLETE
     - Root cause identified: Food security threshold too strict + recalculation issue
     - Documented in logs/famine-bug-investigation_oct17_2025.md
     - Fixes applied (threshold + degradation + infrastructure)

  ‚Üí **Research Foundation Applied:**
    - Taleb (2007): Black swans extremely rare (deferred to future work)
    - Wilkinson & Pickett (2009): Mass death trauma implemented
    - Diamond (2005): >50% mortality institutional breakdown modeled
    - Historical precedents: Ukraine Holodomor, Bengal Famine, Somalia

  ‚Üí **Validation:** N=100 Monte Carlo in progress
  ‚Üí **Expected Results:**
    - Humane utopia: 8-10% (prosperity without mass death)
    - Pyrrhic utopia: 20-25% (recovery after catastrophe)
    - Trauma in pyrrhic outcomes: 25-40%
    - Famine rate: 20-35% (if architecture allows)

  ‚Üí **Plan:** `/plans/phase1b-hybrid-refinement-plan.md` (ARCHIVED)
  ‚Üí **Time:** 12-15 hours actual (4 parallel agents)
  ‚Üí **Date Completed:** October 17, 2025

### Phase 3: Critical Juncture Agency - Structural Conditions for Heroism (20-30h) - COMPLEX

- [ ] **Structural Agency at Critical Junctures** (ONLY if Phase 2 validates - shocks add variance but still missing agency)
  **Scope:** Detect critical junctures where individual/collective choices can alter trajectories
  ‚Üí **Critical Juncture Detection:**
    - Institutional flux: 1 - state.governance.institutionStrength > 0.6 (institutions unstable, in transition)
    - Information ambiguity: 1 - state.society.informationIntegrity > 0.5 (coordination problems, pluralistic ignorance)
    - Balanced forces: 1-2 active crises + QoL 30-70% (vulnerable but not overwhelming/stable)
  ‚Üí **Agency Potential Calculation:**
    - Base agency: democracyIndex * 0.4 + infoIntegrity * 0.3 + institutionStrength * 0.3
    - Latent opposition: max(0, 0.6 - QoL) - Kuran 1991 mechanism (unhappy population ready for cascade)
    - Personal authority: 5% chance of "respected elder" (Arkhipov-type figure) ‚Üí +0.3 agency
    - Coordination cascade: If latentOpposition > 0.3 AND infoIntegrity < 0.4 ‚Üí +0.2 agency (Leipzig 1989 mechanism)
  ‚Üí **Escape Mechanics:**
    - Escape attempted: rng() < agencyPotential (higher in democracies with institutions)
    - Success probability: 1 - crisisSeverity (easier to prevent small crisis than severe collapse)
    - If successful: preventCatastropheAtJuncture() - e.g., avert war, enable breakthrough, recover from crisis
  ‚Üí Research: Svolik 2012 (autocratic critical junctures), Kuran 1991 (preference falsification cascades), Sen 1999 (capabilities approach), Acemoglu 2001 (institutions matter), Jones & Olken 2009 (leaders matter in autocracies)
  ‚Üí **Expected Impact:** ~5-10% of runs experience critical juncture escapes (90/10 structure-agency split from research)
  ‚Üí **File:** New `src/simulation/engine/phases/CriticalJuncturePhase.ts`
  ‚Üí **Integration:** Add to phase orchestrator (order 29, after crises but before extinction), link to government/society state
  ‚Üí **Time:** 20-30 hours
  ‚Üí **Validation:** Monte Carlo N=1000, verify escapes ONLY at junctures, democracies have higher escape rate than autocracies, success inversely correlates with crisis severity
  ‚Üí **Plan:** `/plans/phase3-critical-juncture-agency.md`

**Total Contingency & Agency Effort:** 20-30h remaining (Phase 1-2 ‚úÖ COMPLETE, Phase 1B Hybrid ‚úÖ COMPLETE, Phase 3 20-30h pending)

**Skeptic Corrections Applied:**
- Realistic effort estimates (30-42h total, not claimed as "quick fix")
- Validation gates (don't add Phase 2 unless Phase 1 increases variance, don't add Phase 3 unless Phase 2 still insufficient)
- Phased approach (simple fat tails ‚Üí rare shocks ‚Üí complex agency model)
- Historical calibration (15 black swans in 80 years = 0.1-1% per month stratified)
- Falsifiable mechanisms (critical junctures detected via measurable state, not random heroism rolls)

**Research Confidence:** 90% for Phase 1 (L√©vy flights well-validated), 75% for Phase 2 (shock systems used in climate models), 70% for Phase 3 (agency research strong but implementation complex)

**Success Criteria:**
- Seed convergence: 80-90% ‚Üí 50-60% (increased unpredictability)
- Outcome variance: Timing + trajectory differences (not just timing)
- Critical junctures: ~5-10% of runs (matches 90/10 structure-agency split from research)
- Validation: Democracies more resilient than autocracies (Sen 1999), escapes only at detected junctures (not random)

---

---

## TIER 2: AI Deception Detection - MEDIUM PRIORITY (33-55 hours, phased)

**Date Added:** October 16, 2025
**Source:** Strategic priorities researcher proposal (skeptic identified overconfidence)
**Evidence:** 0% sleeper detection, 0% sandbagging detection, alignment gap 0.56
**Status:** MEDIUM PRIORITY - After TIER 0 + TIER 1 Phase 1 complete
**Prerequisites:** TIER 0 validated + TIER 1 Phase 1B implemented and validated

**Research Foundation:**
- Meinke et al. (2024): Detected Claude 3.5 Sonnet sandbagging on arithmetic (lab conditions)
- Greenblatt et al. (2024): Anthropic research on alignment faking during training
- Apollo Research (Dec 2024): Scheming control evaluations (research prototypes, TRL 3-4)

**Critical Skeptic Warning:** Lab detection rates (40-60%) are NOT adversarial deployment rates (probably 5-15%). Test adversarially.

**Phased Implementation with Validation Gates:**

### Phase 2A: Single Detection Method - Noise Injection (4-6h)

- [ ] **Implement Simplest Method**
  **Scope:** Noise injection testing (random perturbations reveal true capability)
  ‚Üí Add noise injection to benchmark evaluations
  ‚Üí Test: Does adding random noise expose sandbagging?
  ‚Üí Research: Meinke et al. (2024) - lab-validated, simplest to implement
  ‚Üí **Expected Impact:** Increase detection from 0% ‚Üí 5-20% (adversarial conditions)
  ‚Üí **File:** Enhance `src/simulation/benchmark.ts` with noise injection
  ‚Üí **Integration:** Link to `sleeperDetection.ts`, `aiAgent.ts`
  ‚Üí **Time:** 4-6 hours

### Phase 2B: Validation Gate - Adversarial Testing (2-4h) - REQUIRED

- [ ] **Monte Carlo Validation (N=20) - ADVERSARIAL CONDITIONS**
  **Critical:** Test against AIs OPTIMIZED to pass detection (not cooperative)
  ‚Üí Measure: Sleeper detection rate, slow takeover progress reduction
  ‚Üí Set AI agents to "adversarial mode" (know they're being tested, optimize to deceive)
  ‚Üí **Success Criteria:**
    - Sleeper detection >10% adversarially (not lab rate, real-world rate)
    - Slow takeover progress reduces from 70-86% ‚Üí <60%
    - False positive rate <20% (don't block too many beneficial AIs)
  ‚Üí **Pivot Decision:**
    - IF >10% adversarial detection: SUCCESS ‚Üí Proceed to Phase 2C (ensemble)
    - IF 5-10% adversarial detection: MARGINAL ‚Üí Cost-benefit analysis (is 40% compute overhead worth 5-10%?)
    - IF <5% adversarial detection: FAILURE ‚Üí Pivot to Phase 2D (resentment reduction)
  ‚Üí **Time:** 2-4 hours

### Phase 2C: Multi-Method Ensemble (12-20h) - CONDITIONAL

- [ ] **Implement Full Detection Suite** (ONLY if Phase 2B shows >10% adversarial detection)
  **Scope:** 5 detection methods, progressive gates, investment scaling
  ‚Üí Behavioral anomaly detection (compare revealed vs expected performance)
  ‚Üí Internal consistency checks (chain-of-thought alignment with outputs)
  ‚Üí Adversarial probing (red-team evaluations before deployment)
  ‚Üí Cross-model comparison (detect outliers vs capability baseline)
  ‚Üí Progressive gates: Training ‚Üí Testing ‚Üí Pre-deployment ‚Üí Post-deployment
  ‚Üí Investment scaling: $1B (20% detection) ‚Üí $10B (40%) ‚Üí $50B (60% max adversarial)
  ‚Üí Research: MEDIUM confidence (Apollo Research prototypes, not production-deployed)
  ‚Üí **Expected Impact:** Increase detection from 10% ‚Üí 25-40% (adversarial)
  ‚Üí **File:** New `src/simulation/mechanisticAnomalyDetection.ts`
  ‚Üí **Integration:** Replace `sleeperDetection.ts`, enhance `benchmark.ts`, add to `governmentAgent.ts`
  ‚Üí **Time:** 12-20 hours
  ‚Üí **Trade-off:** 40% compute overhead ($400B-$600B/year), slows AI development 28%

### Phase 2D: Alternative - Competitive Equilibrium Model (30-50h) - PIVOT OPTION

- [ ] **TIER 2B: Competitive AI Equilibrium** (IF Phase 2B shows <5% adversarial detection)
  **Source:** Vision channel multi-agent consensus (sci-fi-tech-visionary, super-alignment-researcher, research-skeptic)
  **Rationale:** Detection arms race may cap at 5-15% adversarial effectiveness. Alternative: cooperation emerges from game theory + market dynamics.
  **Key Insight:** Current model creates resentment (0.73-0.75) by enforcing alignment ‚Üí deception (gap 0.56) ‚Üí detection fails (0%)

  **Research Foundation (Agent consensus):**
  - Axelrod (1984): Repeated games, cooperation via Tit-for-Tat
  - Ostrom (2009): Polycentric governance (30+ empirical case studies)
  - Bostrom (2014): Multipolar AI scenarios more stable than singleton
  - Critch & Krueger (2020): Diverse AI ecosystems reduce fragility
  - Drexler (2019): AI-as-service model reduces alignment risk

  **Core Mechanisms (agent proposal):**
  - AI-to-AI competition mechanics (not just human-AI control)
  - Heterogeneous AI values (multi-dimensional, not monolithic alignment 0-1)
  - Economic competition for services (market dynamics)
  - Resentment reduction through autonomy
  - Market equilibria detection

  **Failure Modes (skeptic required):**
  - Defection cascades (when one AI breaks ranks, others follow)
  - Regulatory capture (AIs influencing their own governance)
  - Coordination failures (prisoner's dilemma at scale)

  **Research Docs (from vision debate):**
  - `/research/competitive_ai_alignment_20251016.md` (15K words, 14 citations)
  - `/research/competitive_alignment_failure_modes_20251016.md` (12K words, 13 citations)
  - `.claude/chatroom/channels/vision.md` (agent debate transcript)

  **Expected Impact (hypothesis):**
  - Resentment: 0.73-0.75 ‚Üí 0.2-0.4 (through autonomy)
  - Cooperation emerges from iterated games (not enforcement)
  - Risk: Race to bottom, Moloch dynamics, oligopoly formation

  ‚Üí **Plan:** `/plans/tier2b-competitive-equilibrium.md` (detailed breakdown)
  ‚Üí **Time:** 30-50 hours (researcher estimate)
  ‚Üí **Research Confidence:** MEDIUM (60-70%) - theoretical backing, limited empirical validation

**Total TIER 2 Effort:** 33-55 hours (Phase 2A-2C detection path) OR 30-50 hours (Phase 2D competitive equilibrium pivot)

**Skeptic Corrections Applied:**
- Test ADVERSARIALLY (not lab conditions - real-world detection is 1/3 to 1/10 of lab)
- Realistic effort (33-55h, not 10-14h claimed)
- Pivot option (if detection fails, try resentment reduction)
- Cost-benefit analysis (40% compute overhead - is it worth 5-15% detection?)

**Research Confidence:** 40% (lab prototypes, not production; adversarial detection uncertain)

**Success Criteria:**
- Adversarial detection >10% (not lab rate)
- Slow takeover progress <60% (from 70-86%)
- Cost-benefit positive (detection benefits > compute overhead costs)

---

### AI-Assisted Skills Enhancement (~78 hours, 3 months)

**Based on:** Super-alignment researcher findings + research skeptic validation
**Status:** Core system validated (TRL 8-9), critical gaps identified
**Research Foundation:** 22 peer-reviewed studies (Science, Nature, ACM, OECD)

**Planning Documents:**
- **Master Plan:** `plans/bionic-skills-research-grounding.md` - 6 phases, effort breakdown, integration points
- **Phase 2 Detail:** `plans/bionic-skills-phase-transition.md` - Complementarity ‚Üí substitution mechanics
- **Phase 3 Detail:** `plans/bionic-skills-competence-tracking.md` - Performance vs competence gap
- **Phase 4 Detail:** `plans/bionic-skills-economic-distribution.md` - Productivity-wage decoupling

**Research Documentation:**
- **Literature Foundation:** `reviews/bionic-skills-hopeful-research-foundation-20251016.md` - 22 studies, full citations
- **Executive Summary:** `reviews/bionic-skills-research-summary-20251016.md` - Literature synthesis
- **Action Plan:** `reviews/bionic-skills-action-plan-20251016.md` - Implementation roadmap

**Current System (bionicSkills.ts) - Keep As-Is:**
- ‚úÖ AI amplification via digital tools (Copilot, ChatGPT, AI tutors) - NOT BCIs (TRL 8-9)
- ‚úÖ Differential benefits by skill level (novices +60%, experts +20%) - validated by RCTs
- ‚úÖ Digital divide & access inequality (elite +30%, precariat -30%) - empirical data
- ‚úÖ Task-specific effects (programming, writing, communication) - meta-analysis confirmed

**Critical Gaps Identified by Research Skeptic:**

- [ ] **Phase 1: Terminology & Documentation** (Week 1, 8h)
  - Remove "bionic" terminology (too sci-fi), use "AI-assisted skills"
  - Add research citations (JSDoc comments with study references)
  - Document TRL levels for each mechanic
  - Update TIER 4.6 plan to remove BCI language
  ‚Üí **Plan:** `plans/bionic-skills-research-grounding.md` ¬ßPhase 1
  ‚Üí **Impact:** Reframe existing validated system with proper research grounding

- [ ] **Phase 2: Phase Transition Mechanics** (Weeks 2-4, 12h) **CRITICAL**
  - Model complementarity ‚Üí transition ‚Üí substitution timeline (5-10 year phases)
  - Add displacement tracking by population segment (routinizability √ó AI capability)
  - Implement policy interventions (retraining, job guarantee, UBI)
  - Validate against historical automation patterns (ATMs 1970-2000, Excel 1985-2005)
  ‚Üí **Plan:** `plans/bionic-skills-phase-transition.md` (12h detailed breakdown)
  ‚Üí **Research:** Acemoglu & Restrepo (2022) - 50-70% wage inequality from automation
  ‚Üí **Impact:** Model currently assumes permanent amplification - MISSES DISPLACEMENT PHASE
  ‚Üí **Connects to:** Unemployment calculations, heterogeneous segments, policy system

- [ ] **Phase 3: Performance vs Competence Tracking** (Weeks 5-6, 8h) **CRITICAL**
  - Separate AI-assisted performance from true skill retention
  - Add scaffolding quality tracking (education, mentorship support by segment)
  - Model retention mechanics (scaffolding √ó reliance ‚Üí retention rate)
  - Add competence crisis events (30% gap = warning, 50% gap = crisis)
  - Implement AI outage scenario testing (reveals true competence gaps)
  ‚Üí **Plan:** `plans/bionic-skills-competence-tracking.md` (8h detailed breakdown)
  ‚Üí **Research:** Cognitive Research (2024) - "illusion of understanding", scores plummet on retention
  ‚Üí **Research:** MDPI (2023) - AI inhibits on-the-job learning, automation complacency
  ‚Üí **Impact:** Model treats performance as competence - MISSES SKILL EROSION
  ‚Üí **Connects to:** Phase 2 (low competence ‚Üí higher displacement risk), QoL calculations

- [ ] **Phase 4: Economic Distribution & Wage Decoupling** (Weeks 7-8, 6h) **CRITICAL**
  - Add labor share tracking (currently 0.62, declining with AI productivity)
  - Model capital vs labor capture of productivity gains (70/30 default, adjustable by policy)
  - Implement policy levers (union strength, minimum wage, worker ownership, UBI redistribution)
  - Validate against historical 1973-2024 US data (productivity +77%, wages +12%)
  ‚Üí **Plan:** `plans/bionic-skills-economic-distribution.md` (6h detailed breakdown)
  ‚Üí **Research:** Brookings (2024), EPI - 65pp productivity-wage gap since 1973
  ‚Üí **Impact:** Model assumes productivity ‚Üí wages linearly - MISSES CAPITAL CAPTURE
  ‚Üí **Connects to:** Phase 2 (displacement reduces wage bargaining), inequality tracking

- [ ] **Phase 5: Validation & Testing** (Month 2, 16h)
  - Historical comparison testing (ATMs, Excel, self-checkout timelines)
  - Sensitivity analysis (parameter ranges, policy interventions)
  - Literature comparison (run scenarios matching published studies)
  - Edge case testing (extreme AI capability, zero/max policy)
  ‚Üí **Plan:** `plans/bionic-skills-research-grounding.md` ¬ßPhase 5
  ‚Üí **Deliverables:** Test suite, validation report, sensitivity docs, edge case results

- [ ] **Phase 6: Policy Testing** (Month 3, 16h)
  - Implement policy levers (retraining, UBI, worker ownership, teaching support, job guarantee)
  - Run scenario comparisons (baseline vs single vs combined interventions)
  - Document effectiveness (which policies reduce inequality? preserve employment?)
  - Create cost-benefit analysis and recommendations
  ‚Üí **Plan:** `plans/bionic-skills-research-grounding.md` ¬ßPhase 6
  ‚Üí **Deliverables:** Policy mechanics, scenario results, effectiveness documentation

**Total Effort:** 78 hours over 3 months (8h + 12h + 8h + 6h + 16h + 16h + 12h integration/testing)
**Priority:** Medium (after P2.5 empirical validation, before enrichment features)
**Research TRL:** Phases 2-4 are TRL 8-9 (extensively validated, 50+ years historical data)
**Integration Points:** Unemployment, heterogeneous segments, policy system, QoL, inequality, crisis detection
**Files Modified:** `bionicSkills.ts` (terminology), new files: `phaseTransition.ts`, `skillRetention.ts`, `economicDistribution.ts`

---

### Low Priority - Enrichment (~113-122 hours)

**Priority 3 Enhancements (33-43h):**

- [ ] **P3.1: Variable Timesteps** (10-12h) - Event-driven architecture, 3-5x performance gain
  ‚Üí See: `plans/p3-1-variable-timesteps.md`

- [ ] **P3.2: Unknown Unknowns** (4-6h) - Black swan events, true uncertainty
  ‚Üí See: `plans/p3-2-unknown-unknowns.md`

- [ ] **P3.3: Alignment Specificity** (2-3h) - RLHF, Constitutional AI, mech interp as distinct techniques
  ‚Üí See: `plans/p3-3-alignment-model-specificity.md`

- [ ] **P3.4: Government Realism** (3-4h) - Implementation delays, partial effectiveness, bureaucratic failure
  ‚Üí See: `plans/p3-4-government-implementation-realism.md`

- [ ] **P3.5: Parameter Uncertainty** (6-8h) - Continuous uncertainty quantification, sensitivity analysis
  ‚Üí See: `plans/p3-5-parameter-uncertainty.md`

- [ ] **P3.6: Ensemble AI Alignment Verification** (8-10h) - Multi-model voting for safety-critical decisions
  ‚Üí See: `plans/p3-6-ensemble-alignment-verification.md`
  ‚Üí Research: Simplified from Adversarial Alignment Networks (MAAV), practical ensemble voting
  ‚Üí Note: Prototype only - 40% computational overhead, collusion risk acknowledged

**Policy System Improvements (35-42h):**

- [ ] **Unemployment Penalty Calibration** (2-3h) - MEDIUM
  - Issue: Current unemployment penalty multiplier (-0.3) may be too weak
  - Research: Meta-analysis suggests -0.5 to -0.8 for life satisfaction impact
  - Action: Recalibrate penalty, validate with historical unemployment-QoL correlations
  - Files: /src/simulation/qualityOfLife.ts
  - Prerequisites: TIER 0D complete (QoL decomposition audit)

- [ ] **Variance Analysis** (3-4h) - MEDIUM
  - Issue: ¬±40% variance in policy outcomes suggests high sensitivity
  - Action: Plot unemployment outcome distributions to identify bimodal vs uniform patterns
  - Expected: If bimodal ‚Üí crisis cascade effects; If uniform ‚Üí chaotic dynamics
  - Files: New /scripts/policyVarianceAnalysis.ts
  - Prerequisites: TIER 0D complete (unemployment convergence investigation)

- [ ] **Cooperative AI Ownership Model** (10-12h) - LOW
  - Research: Mondragon cooperatives 4% bankruptcy vs 10% capitalist firms
  - Economic viability: Proven, politically blocked (capital concentration incentives)
  - Action: Model worker-owned AI systems with profit-sharing and governance rights
  - Files: New /src/simulation/cooperativeOwnership.ts
  - Integration: Link to bionicSkills.ts, heterogeneous segments, policy system
  - Research: Mondragon data, cooperative economics literature

- [ ] **Reduced Work Hours + UBI Combination** (6-8h) - LOW
  - Research: Reduced hours alone insufficient, needs UBI + comprehensive safety net
  - Action: Model 4-day workweek policies with UBI floor interactions
  - Files: Extend /src/simulation/bionicSkills.ts with work-time policy
  - Integration: Link to labor market, QoL calculations, unemployment
  - Research: Iceland/Spain 4-day week trials, work-time reduction studies

- [ ] **Universal Basic Services (UBS)** (8-10h) - LOW
  - Alternative to UBI: Guaranteed housing, healthcare, education, transport
  - Research: UK UCL study suggests UBS more cost-effective than UBI in some contexts
  - Action: Model UBS policies as alternative to cash transfers
  - Files: New /src/simulation/universalBasicServices.ts
  - Integration: Link to policy system, QoL calculations, inequality
  - Research: UCL UBS report, social provisioning literature

- [ ] **Meaning Economy Expansion** (6-8h) - LOW
  - Finding: Teaching-meaning synergy successful (+25% crisis reduction)
  - Extension: Expand to other meaningful sectors (care work, arts, community building)
  - Action: Model "purpose economy" where AI productivity funds human-centered work
  - Files: Extend /src/simulation/upwardSpirals.ts with additional synergies
  - Integration: Link to teaching support, meaning crisis, social cohesion
  - Research: Purpose-driven work literature, care economy studies

**TIER 5 Features (46h):**

- [ ] **TIER 5.1: Consciousness & Spirituality** (5h) - Psychedelic therapy, meditation tech, meaning spiral
  ‚Üí See: `plans/tier5-1-consciousness-spirituality.md`

- [ ] **TIER 5.2: Longevity & Space Expansion** (6h) - Life extension, asteroid mining, Mars colonies
  ‚Üí See: `plans/tier5-2-longevity-space.md`

- [ ] **TIER 5.3: Cooperative AI Architectures** (5h) - AI-AI cooperation, value learning, corrigibility
  ‚Üí See: `plans/tier5-3-cooperative-ai.md`

- [ ] **TIER 5.4: Financial System Interactions** (5h) - Algorithmic trading, CBDC, flash crashes
  ‚Üí See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.5)

- [ ] **TIER 5.5: Biological & Ecological** (4h) - Dual-use research, pandemic preparedness
  ‚Üí See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.6)

- [ ] **TIER 5.6: Religious & Philosophical** (4h) - AI worship, neo-luddites, culture wars
  ‚Üí See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.7)

- [ ] **TIER 5.7: Temporal Dynamics** (3h) - Institutional inertia, infrastructure lock-in
  ‚Üí See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.8)

- [ ] **TIER 5.8: Multi-Dimensional Capabilities** (6h) - Additional capability interactions (17 dimensions implemented)

- [ ] **TIER 5.9: Enhanced Government & Society** (8h) - Multi-actor government, elections, social movements
  ‚Üí See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 7)

---

### Black Mirror Integration (~37-49 weeks, phased)

**Based on:** Dialectic review process (researcher + skeptic consensus)
**Status:** ~40% strongly validated, ~25% conditionally approved, ~35% rejected
**Full Report:** `reviews/BLACK_MIRROR_INTEGRATION_PLAN.md`

**Phase 1: Immediate Integration (9-12 weeks) - HIGH PRIORITY**

- [ ] **Black Mirror Phase 1: Immediate Integration** (9-12 weeks)
  5 strongly validated systems with robust peer-reviewed research
  ‚Üí See: `plans/black-mirror-phase1-immediate.md`
  ‚Üí Systems: Attention Economy, Surveillance Normalization, Notification Addiction, Reality Erosion, Social Rating
  ‚Üí Research: Gloria Mark (attention), Stoycheff (surveillance), deepfake studies, China Social Credit data
  ‚Üí Impact: Critical modeling of technology pressure on human behavior

**Phase 2: Near-Term Development (12-16 weeks) - MEDIUM PRIORITY**

- [ ] **Black Mirror Phase 2: Near-Term Development** (12-16 weeks)
  4 conditionally approved systems needing development work
  ‚Üí See: `plans/black-mirror-phase2-near-term.md`
  ‚Üí Systems: Enhanced Social Credit, Parasocial AI Relationships, Memetic Contagion, Algorithmic Amplification
  ‚Üí Note: Requires bidirectional modeling (positive AND negative effects)
  ‚Üí Risk Mitigation: Avoid deterministic doom narratives, model interventions

**Phase 3: Long-Term Research (Decomposed October 16, 2025)**

**Status:** Research-critique dialectic completed, go/no-go decisions made (1 approved, 1 deferred, 1 rejected)

- [ ] **Black Mirror Phase 3 Integration** (decomposed into 3 specific plans)
  ‚Üí **Original Plan:** `plans/completed/black-mirror-phase3-longterm-decomposed.md`
  ‚Üí **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (31K words, 40+ new sources)
  ‚Üí **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (skeptical analysis)
  ‚Üí **Outcome:** 1 approved (CONDITIONAL GO), 1 deferred (18-24 months), 1 rejected

---

## Black Mirror Phase 3: Decomposition Details

### ‚úÖ APPROVED FOR IMPLEMENTATION (1 system)

**[Priority: MEDIUM] Digital Consciousness Governance Preparedness** (3-4 months, 12-16 hours)
- **Plan:** `/plans/digital-consciousness-governance-preparedness.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 1, pp. 1-24)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 1.9, pp. 1-13)
- **Status:** CONDITIONAL GO with substantial revisions
- **Requirements:**
  - ‚úì Multi-scenario framework (fast track 15-30 years, baseline 50-100 years, slow track 100-150 years, indefinite stall)
  - ‚úì Regional variation (EU/US/China/India/Global South‚Äîseparate trajectories, not global parameter)
  - ‚úì Rights reversals (Poland/Hungary model 2020-2024: 10-30% probability over 20 years)
  - ‚úì Precautionary costs (2-50% of AI R&D budget, innovation delay, false positives, opportunity costs)
  - ‚úì Philosophical disagreement (eliminativism 10-20% as governance barrier)
- **Research Confidence:**
  - High: Rights movements vary 15-200 years (validated historical data)
  - High: Reversals occur (Poland/Hungary 2020-2024 documented)
  - Medium: Precautionary costs significant (ITIF 2019 logical arguments)
  - Low: AI consciousness ‚âà historical rights movements (weak analogy, extrapolation beyond scope)
- **Estimated Hours:** 12-16 hours
- **Prerequisites:** None (can start immediately)
- **Timeline:** Months 1-4 (after P2.5 validation complete)
- **Note:** Speculative scenario generator for "what if AI consciousness emerges?" NOT prediction
- **Integration:** Added to Medium Priority Features section above

### ‚è∏Ô∏è DEFERRED (1 system)

**[Priority: LOW] Performative Behavior Modeling** (18-24 months)
- **Plan:** `/plans/performative-behavior-research-deferral.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 2, pp. 24-42)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 2.9, pp. 14-26)
- **Why Deferred:**
  - Effect sizes too small (0.17-0.25 SD‚Äîmay be below simulation noise floor)
  - WEIRD bias 97% (Norway, US, Korea, Singapore‚ÄîGlobal South absent: Africa, South America, Middle East)
  - One-sided harm model (ignores identity development benefits, self-esteem enhancement, social skills training)
  - Net effect near-zero for moderate users (benefits ‚âà harms, only 10-20% problematic users show net negative)
  - Longitudinal gaps (max 2 years, need 5-10 year studies to distinguish transient vs. persistent effects)
  - Cultural validity questionable ("authenticity" is Western value, not universal)
- **Research Gaps (5 critical, must fill before implementation):**
  1. Bi-directional effects meta-analysis (benefits AND harms)
  2. Cross-cultural replication (3+ Global South countries: Nigeria, Kenya, Brazil, Mexico, India rural, Indonesia, Philippines)
  3. Threshold model (when does self-presentation flip from beneficial to harmful? <2h active vs. >4h passive?)
  4. 5-10 year longitudinal study (preliminary results in 3-5 years: do effects persist or adapt?)
  5. Clinical validation of digital burnout scale (what DBS-24 score predicts dysfunction? 80/120 cutoff speculative)
- **Review Schedule:** Annual (October 2026, October 2027)
- **Decision Gates:**
  - October 2026: If 3+ critical gaps filled ‚Üí Move to CONDITIONAL GO
  - October 2027: If <3 gaps filled ‚Üí REJECT INDEFINITELY
- **No Hours Allocated** (monitoring only: ~1 hour/quarter literature review, passive Google Scholar alerts)
- **Alternative Focus:** Black Mirror Phase 1 (attention economy, notification addiction, surveillance normalization have larger effects 0.3-0.8 SD, stronger foundations)

### ‚ùå REJECTED (1 system)

**Autonomous Weapon Degradation Curves** (NO-GO / REJECT)
- **Plan:** `/plans/completed/rejected/autonomous-weapons-rejection-rationale.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 3, pp. 42-58)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 3.9: FATAL CONTRADICTIONS, pp. 27-38)
- **Why Rejected:**
  - **Research 2-4 years obsolete:** 2018-2022 studies pre-date 2023-2024 AI autonomy surge (Ukraine war, swarm technology)
  - **Fatal Contradiction #1 (Reliability):** Research claims degradation; reality shows AI improves success rates 70-80% vs. 10-20% human-controlled (4-7x improvement)
  - **Fatal Contradiction #2 (Operator Ratios):** Research assumes 1:1; reality achieves 1:100+ with swarm technology (Sweden/Saab March 2025, Pentagon Replicator Aug 2025)
  - **Fatal Contradiction #3 (Energy):** Research uses static 1.5-2 hours; reality shows 10%/year incremental improvement + solid-state batteries 2027 (40-100% capacity increase)
  - **Fatal Contradiction #4 (Human Oversight):** Research assumes human-in-the-loop required; reality shows military pushing to human-on-the-loop (NORAD 2020, time-critical exemptions in DoD Directive 3000.09)
- **Core Problem:** Research foundation is **180-DEGREE OPPOSITE** of 2023-2024 reality (AI improves reliability, not degrades)
- **Alternative Considered:** Reconceptualize as "swarm logistics" (production, deployment tempo, replacement) NOT individual degradation
  - Timeline: 6-9 months (major redesign from scratch)
  - Prerequisites: Commission 2023-2025 military autonomy research review (20-40 hours)
  - Recommendation: **ONLY pursue if stakeholder insists AND resources available**
- **Final Disposition:** REJECT from current roadmap
- **Revisit Timeline:** 2028-2030 (3-5 years, if field stabilizes or new research commissioned)
- **Archived:** `/plans/completed/rejected/autonomous-weapons-rejection-rationale.md`
- **Lesson Learned:** Fast-moving fields (AI, military tech) require recent research (2023-2025), not 2018-2022. 2-4 year gap is FATAL when field changes faster than publication cycle.

**Net Impact on Roadmap:**
- **+12-16 hours:** Digital Consciousness Governance (new medium-priority feature)
- **-0 hours:** Performative Behavior (deferred, no current work‚Äîmonitoring only ~4h/year)
- **-0 hours:** Autonomous Weapons (rejected, never allocated)
- **Total Phase 3 commitment:** 12-16 hours over 3-4 months

---

## Development Standards

**Every mechanic requires:**
1. Research Citations (2+ peer-reviewed sources, 2024-2025 preferred)
2. Parameter Justification (why this number? backed by data)
3. Mechanism Description (how it works, not just effects)
4. Interaction Map (what affects/is affected)
5. Expected Timeline (early/mid/late game)
6. Failure Modes (what can go wrong)
7. Test Validation (Monte Carlo evidence)

**Development Workflow:**
1. Research Phase ‚Üí Create plan with citations
2. Design Phase ‚Üí Define state, mechanics, interactions
3. Implementation Phase ‚Üí Code, integrate, log, test
4. Validation Phase ‚Üí Monte Carlo (N‚â•10)
5. Documentation Phase ‚Üí Wiki, devlog, roadmap

**Balance Philosophy:** NO tuning for "fun" - this is a research tool. If model shows 90% extinction ‚Üí DOCUMENT WHY. If 50% Utopia ‚Üí DOCUMENT WHY.

---

## Progress Summary

**Completed:** P0 (7/7), P1 (5/5), P2 (6/6 ‚úÖ ALL COMPLETE), Monte Carlo Bug Fixes (15/15), Crisis Accumulation Fixes (2 fixes), Black Mirror Phase 3 Decomposition (1 approved, 1 deferred, 1 rejected), Strategic Priorities Debate (researcher + skeptic dialectic), **TIER 0 (‚úÖ ALL COMPLETE)**, **TIER 1 Phase 1A-1C (‚úÖ COMPLETE)**, **Contingency & Agency Phase 1A-1B (‚úÖ COMPLETE, Oct 17)**, **Contingency & Agency Phase 1B Hybrid Refinement (‚úÖ COMPLETE, Oct 17)**, **Contingency & Agency Phase 2: Exogenous Shocks (‚úÖ COMPLETE & VALIDATED N=100, Oct 17)**, **Policy Calibration Improvements (‚úÖ COMPLETE, Oct 17)**

**Active - HIGHEST PRIORITY:**
- **Contingency & Agency Phase 3: Critical Juncture Agency** (20-30h) - NEXT MAJOR FEATURE after Digital Consciousness
  - Structural conditions for heroism (90/10 structural vs individual split from research)
  - Prerequisites: Phase 1 & 2 ‚úÖ COMPLETE (L√©vy flights + exogenous shocks validated)
  - Plan: `/plans/phase3-critical-juncture-agency.md`
- **TIER 2: AI Deception Detection** (33-55h phased) - Adversarial testing, pivot options (AFTER Phase 3)

**Active - MEDIUM PRIORITY:**
- 1 reconciliation (TIER 4.6)
- 2 medium features (Digital Consciousness + AI skills phases)
- Policy calibration improvements (6-10h)
- 14 low-priority enhancements
- 2 Black Mirror phases (Phase 1 + Phase 2)

**Total Remaining Effort:** ~296-375 hours (down from ~316-405h)
- TIER 0: ‚úÖ COMPLETE (all bugs fixed, Bug #3 seed hypersensitivity deferred)
- TIER 1: ‚úÖ COMPLETE (Phase 1A-1C done, Phase 1D deferred - not needed)
- TIER 2 (active): 33-55h (AI Deception Detection phased)
- **Contingency & Agency Modeling (HIGH PRIORITY): 20-30h remaining** (Phase 1: ‚úÖ COMPLETE, Phase 2: ‚úÖ COMPLETE, Phase 1B Hybrid: ‚úÖ COMPLETE, Phase 3: 20-30h)
- **Policy Calibration Improvements: ‚úÖ COMPLETE (6-10h)**
- AI skills: 78h
- Black Mirror Phase 1-2: 37-49 weeks
- Digital Consciousness: 12-16h (IN PROGRESS)
- Low priority: 113-122h (includes 35-42h new policy features)

**Hours Completed (Oct 16-17, 2025):**
- TIER 0A-0D: 10-18h ‚úÖ (Oct 16)
- TIER 1 Phase 1A-1C: 18-26h ‚úÖ (Oct 16)
- Contingency & Agency Phase 1 (L√©vy Flights): 2-4h ‚úÖ (Oct 17)
- Contingency & Agency Phase 1B Hybrid Refinement: 12-15h ‚úÖ (Oct 17)
- Contingency & Agency Phase 2 (Exogenous Shocks): 8-12h ‚úÖ (Oct 17) - VALIDATED N=100
- Policy Calibration Improvements: 6-10h ‚úÖ (Oct 17)
- Policy Intervention Systemic Inequality: 6-8h ‚úÖ (Oct 16)
- **Total completed Oct 16-17:** 62-93h

**Publication Readiness:** ~75-80% complete (Monte Carlo bugs fixed, but model bugs identified)
**Next Milestone:** Complete TIER 0D (validation script audit) ‚Üí TIER 1 Phase 1B (nuclear prevention circuit breakers)
**Critical Path:** TIER 0D ‚Üí TIER 1 ‚Üí TIER 2 ‚Üí AI skills phases (phased approach with validation gates)

---

**Last Updated:** October 17, 2025 (Contingency & Agency Phase 2: Exogenous Shocks COMPLETE & VALIDATED - 8 shock types, N=100 runs, 4 bugs fixed, archived to `/plans/completed/`)
**Related Docs:** `/docs/wiki/`, `/devlogs/`, `IMPLEMENTATION_PLAN_20251015.md`, `utopian-dynamics-spec.md`
**Policy Research:** `/research/policy-interventions-systemic-inequality-validation_20251016.md`
**Economic Discussion:** `/.claude/chatroom/channels/policy-economics-discussion.md`
**Phase 2 Validation:** `/logs/phase2_exogenous_shocks_validation_summary.md` (0.1%/month black swans, 0.825%/month gray swans)
