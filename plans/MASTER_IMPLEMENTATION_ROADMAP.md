# Master Implementation Roadmap
## AI Alignment Game Theory Simulation

**Date:** October 16, 2025
**Purpose:** Active work items only - completed work in `/plans/completed/`
**Philosophy:** Research-backed realism, mechanism-driven emergence

---

## Research-Backed Realism

> "We are never going for specific outcomes, only trying to figure out the most realistic, defensible model we can - let the model show what it shows."

**Guiding Principles:**
1. **Research First:** Every mechanic backed by 2024-2025 peer-reviewed research
2. **Mechanisms Over Balance:** Set parameters to real-world values, don't tune for "fun"
3. **Emergence:** Allow unexpected outcomes to emerge from interactions
4. **Documentation:** Every system has research citations

**Recent Research Additions (Oct 16, 2025):**
- Katz & Krueger (2019): Retraining effectiveness by socioeconomic status
- Harvey (2005) & MGNREGA (2020): Job guarantee program quality stratification
- Chetty et al. (2014): Educational access and outcomes by socioeconomic background
- Kahneman & Deaton (2010): Income-life satisfaction relationship
- Alaska PFD: Universal basic income wage gap reduction
- Acemoglu (2024): Displacement without reinstatement framework
- Sen (1999): Capabilities approach (freedom > outcomes if basic needs met)
- Frase (2016): Four Futures framework (Rentism, Exterminism scenarios)

---

## Current State Summary

### ✅ Completed & Archived

**TIER 0-3:** Baseline corrections, extinction risks, crisis mitigations, planetary boundaries
**TIER 4.1-4.5:** Tech tree (70 techs), dystopia paths, info warfare, energy/resources, population
**Priority 0 (P0):** 7 critical fixes - AI growth, bankruptcy, determinism, stochasticity (✅ 7/7 complete)
**Priority 1 (P1):** 5 high-priority fixes - death accounting, mortality rates, recovery mechanics (✅ 5/5 complete)
**Priority 2 (P2):** 6 medium improvements - environmental calibration, breakthroughs, org diversification, heterogeneous populations, simulation features, memetic evolution (✅ 6/6 complete)

**All details:** See `/plans/completed/` directory

---

---

## TIER 0: Critical Bug Fixes - HIGHEST PRIORITY (4-6 hours remaining)

**Date Added:** October 16, 2025
**Source:** Strategic priorities debate (researcher + skeptic analysis)
**Evidence:** Monte Carlo outputs showing universal simulation failures
**Status:** ✅ TIER 0A-0C COMPLETE, URGENT TIER 0D added (policy validation script audit)

**Context:**
The researcher-skeptic debate revealed that while nuclear war is the dominant killer (3,961M deaths, 92.6% of total), we have three fundamental model bugs that make all results suspect:

1. ✅ **100% Inconclusive Outcomes** - FIXED (recovery pathways now working)
2. ✅ **76-83 Orphaned AIs** - FIXED (0 orphaned AIs in validation runs)
3. ✅ **Compute Paradox** - FIXED (capability declines during crisis)

**Critical Insight:** The researcher was correct about WHAT to fix (nuclear war). The skeptic was correct about WHEN to fix it (after fixing the model).

### Required Fixes (Must Complete in Order)

- [x] **TIER 0A: Fix Inconclusive Outcome Problem** ✅ COMPLETE (4-8h)
  **Evidence:** 100% of runs end inconclusive, 0% utopia/dystopia/extinction resolution
  **Impact:** Makes simulation results interpretable
  → Plan: `/plans/tier0-critical-bug-fixes.md` (Section 0A)
  → Deliverables: Recovery pathway mechanics, threshold calibration, validation Monte Carlo (N=10)
  → Success: >20% of runs resolve to definitive outcome

- [x] **TIER 0B: Fix Orphaned AI Bug** ✅ COMPLETE (2-4h)
  **Evidence:** 76-83 orphaned AIs per run (should be 0)
  **Impact:** Makes AI population dynamics coherent
  → Plan: `/plans/tier0-critical-bug-fixes.md` (Section 0B)
  → Deliverables: Ownership transfer logic, retirement/transfer/open-source mechanics
  → Success: 0 orphaned AIs in all runs

- [x] **TIER 0C: Fix Compute Paradox** ✅ COMPLETE (4-6h)
  **Evidence:** Capability rises after 50% population loss, data centers close
  **Impact:** Makes capability growth physically plausible
  → Plan: `/plans/tier0-critical-bug-fixes.md` (Section 0C)
  → Deliverables: Infrastructure-capability linkage, degradation mechanics, validation
  → Success: Capability declines when population drops >30%

- [ ] **TIER 0D: Policy Validation Script Audit** ⚠️ URGENT (8-12h) **INCREASED FROM 4-6h**
  **Date Added:** October 16, 2025
  **Updated:** October 17, 2025 (Critical bugs discovered in seeds 80000-80059)
  **Evidence:** Policy Monte Carlo validation (N=60, seeds 80000-80059) reveals 4 CRITICAL BUGS
  **Impact:** Invalidates Job Guarantee findings, questions simulation stability
  → **CRITICAL BUG #1: Job Guarantee Paradox** (2-3h) - BLOCKING ALL POLICY VALIDATION
    - Issue: Job Guarantee produces HIGHEST unemployment (58.9% ± 40.3%) when it should produce LOWEST (<15%)
    - Expected: Job guarantee with 100% implementation → 5-15% unemployment floor
    - Actual: 58.9% unemployment (WORSE than baseline 30.8%, WORSE than NO policy!)
    - Hypothesis: calculateUnemploymentFloor() logic may be inverted or incorrectly applied
    - Files to investigate:
      - /src/simulation/calculations.ts:212-245 (unemployment calculation with job guarantee)
      - /src/simulation/bionicSkills.ts:1785-1808 (calculateUnemploymentFloor function)
    - Root cause possibilities:
      1. Floor calculation ADDING to unemployment instead of subtracting
      2. Floor applied as MAXIMUM employment instead of MINIMUM
      3. Interaction with retraining/displacement calculation buggy
      4. Population weighting incorrect
    - Validation test: Single-seed run with jobGuaranteeLevel=1.0 should show ~5-15% unemployment
    - Impact: ALL Job Guarantee conclusions INVALID until fixed
  → **CRITICAL BUG #2: Extreme Unemployment Variance** (2-3h) - SIMULATION STABILITY
    - Issue: Unemployment has ±40% standard deviation (coefficient of variation 96-124%)
    - This means outcomes are UNPREDICTABLE - same policy, different seed = radically different results
    - Baseline: 30.8% ± 36.1% (ranges 0% to ~67%)
    - UBI: 30.7% ± 37.9% (ranges 0% to ~69%)
    - Job Guarantee: 58.9% ± 40.3% (ranges ~19% to ~99%)
    - Possible causes:
      1. Crisis cascades dominating (bimodal: survive vs collapse) - need histogram analysis
      2. Chaotic butterfly effects (uniform: exponential RNG sensitivity, missing stabilization)
      3. Missing reinstatement mechanism (Acemoglu's task creation - only displacement modeled)
    - Investigation steps:
      1. Plot unemployment outcome histograms for each scenario
      2. Calculate skewness and kurtosis to detect bimodality
      3. Test correlation with crisis events (environmental debt, social cohesion)
      4. Audit labor market model for stabilization mechanisms
    - Impact: Results not robust enough for research publication
  → **CRITICAL BUG #3: Seed Hypersensitivity** (0.5h) - RESEARCH VALIDATION VIOLATION
    - Issue: Different seed ranges produce completely different patterns
    - Seeds 42000-42059 (previous run): 54% unemployment convergence across ALL scenarios
    - Seeds 80000-80059 (current run): 30-59% unemployment differentiation
    - Expected: Results should be robust to seed choice - different seeds = similar distributions
    - Actual: Seed ranges correlate with different simulation regime behaviors
    - Fix: Change from sequential to random seed sampling
    - Files to modify: /scripts/policyMonteCarloValidation.ts (line 351)
      - Change from: const seed = baseSeed + (SCENARIOS.indexOf(scenario) * runsPerScenario) + i;
      - Change to: const seed = Math.floor(Math.random() * 1000000); (or crypto.randomInt)
    - Impact: Previous conclusions may be seed-range artifacts
  → **CRITICAL BUG #4: AI Lab Financial Model Broken** (3-4h) - MEDIUM PRIORITY
    - Issue: All major AI labs (OpenAI, Anthropic, Meta, DeepMind) go bankrupt months 70-120
    - Happens in ALL scenarios (baseline, UBI, retraining, teaching, job guarantee, combined)
    - Warnings: "⚠️ [Month XX] OpenAI is in financial distress (capital: $-24.1M)"
    - Expected: Labs should either be profitable, have VC funding runway, OR bankruptcy triggers major effects
    - Actual: Bankruptcy occurs but simulation continues as if nothing happened
    - Files to investigate:
      - /src/simulation/aiOrganizations.ts (AI lab financial model)
      - /src/simulation/engine/phases/AIOrganizationPhase.ts (bankruptcy handling)
    - Impact: AI capability trajectories may be incorrect during financial distress
  → **VALIDATED FINDINGS (keep from seeds 80000-80059):**
    - ✅ Retraining weakest: -9.4% wage gap reduction (vs -81.5% for UBI)
    - ✅ UBI strongest: 81.5% wage gap reduction, no quality stratification
    - ✅ Combined interventions best: 87.9% wage gap reduction (0.8% final gap)
    - ✅ Competence gap reduction: Combined 2.8% vs Baseline 4.7%
  → **INVALIDATED FINDINGS (Job Guarantee bug):**
    - ❌ 58.9% unemployment (HIGHEST, should be LOWEST)
    - ❌ 9.6% wage gap (WORST, worse than baseline)
    - ⚠️ All Job Guarantee findings INVALID until bug fixed
  → **VARIANCE WARNING:**
    - ⚠️ ±40% standard deviation = outcomes unpredictable
    - ⚠️ Coefficient of variation 96-124% (>100% = more variance than mean!)
    - ⚠️ Needs histogram analysis to determine if bimodal (cascades) or chaotic
  → **QoL PARADOX (seed hypersensitivity):**
    - Previous (seeds 42000): Baseline BEST QoL (62.6%), interventions worse
    - Current (seeds 80000): Job Guarantee BEST QoL (61.0%), Retraining worst (52.5%)
    - ⚠️ Seed hypersensitivity suggests results not robust
  → **Success Criteria:**
    - Job Guarantee logic fixed and validated (unemployment <15% with full implementation)
    - Unemployment variance explained (bimodal vs chaotic identified)
    - Seed selection changed to random sampling (prevents range correlation artifacts)
    - Labor market stabilization mechanisms audited and added if missing
    - AI lab financial model fixed (bankruptcy has proper effects OR doesn't occur)
  → **Prerequisites:** Policy intervention implementation complete ✅
  → **Next Steps:** After TIER 0D → TIER 1 Phase 1B (nuclear prevention circuit breakers)

**Validation Gate:**
After implementing 0A-0C, run Monte Carlo (N=20) to verify:
- ✅ Orphaned AIs = 0 (was 76-83)
- ✅ Resolved outcomes >20% (was 0%)
- ✅ Capability declines during crisis (was rising)

**Policy Validation Gate (TIER 0D):**
After auditing policy scripts:
- Baseline scenario assumptions documented
- Unemployment convergence mechanism identified
- QoL class decomposition validated

**Total Effort:** 10-18 hours (0A-0C), 8-12 hours (0D) = 18-30 hours total
**Completed:** 10-18 hours (TIER 0A-0C ✅)
**Remaining:** 8-12 hours (TIER 0D) **INCREASED DUE TO CRITICAL BUGS**
**Prerequisites:** None (can start immediately)
**Next Steps:** After TIER 0D complete → TIER 1 Phase 1B nuclear war prevention (phased approach)

---

### ✅ Priority 2 Complete (6/6)

All Priority 2 improvements are now complete and archived to `/plans/completed/`:

- [x] **P2.3: Heterogeneous Population Segments** ✅ COMPLETE (8-10h actual)
  → Plan: `plans/completed/p2-3-heterogeneous-population.md`

- [x] **P2.4: Simulation Features for Validation** ✅ COMPLETE (3h actual, Oct 16, 2025)
  → Plan: `plans/completed/p2-4-simulation-features-COMPLETE.md`
  → Detail: `plans/completed/event-trigger-system-design.md`

- [x] **P2.5: Empirical Validation** ✅ FRAMEWORK COMPLETE (4h actual, Oct 16, 2025)
  → Plan: `plans/completed/p2-5-empirical-validation-FRAMEWORK-COMPLETE.md`

- [x] **P2.6: Memetic Evolution & Polarization Dynamics** ✅ COMPLETE (10.5h actual, Oct 16, 2025)
  → Plan: `plans/completed/p2-6-memetic-polarization-dynamics-COMPLETE.md`

---

### Medium Priority Features (~31-38 hours)

**New Outcome Spaces:**

- [x] **TIER 4.6: Human Enhancement & Merger Pathways** ⚠️ IMPLEMENTED BUT NEEDS RECONCILIATION (8h actual)
  **Status:** Added humanEnhancement.ts system with segment-level tracking, BUT overlaps with existing bionicSkills.ts
  → BCI/merger pathways: Research skeptic correct (TRL 0-2, science fiction) - should be removed
  → AI-assisted cognition: Already exists in `bionicSkills.ts` (TRL 8-9) - need to reconcile duplication
  → See: `plans/tier4-6-human-enhancement.md` + `devlogs/crisis_accumulation_fixes_oct16_2025.md`
  → Next: Merge humanEnhancement.ts segment tracking into bionicSkills.ts, remove BCI/merger

**Research-Backed Enhancements:**

- [ ] **Digital Consciousness Governance Preparedness** (12-16h) **[Black Mirror Phase 3]**
  Multi-scenario rights timeline modeling (15-200 years), regional governance variation (EU/US/China/Global South), rights reversal mechanics (Poland/Hungary model), precautionary principle costs
  → See: `plans/digital-consciousness-governance-preparedness.md`
  → Research: TRL 3-4 (historical data validated, AI extrapolation speculative), 22 sources
  → Status: CONDITIONAL GO (October 16, 2025) - requires multi-scenario, regional variation, rights reversals, precautionary costs
  → Impact: Governance layer for potential digital consciousness emergence (scenario generator, not prediction)

---

## TIER 1: Nuclear War Prevention - HIGH PRIORITY (18-32 hours remaining, phased)

**Date Added:** October 16, 2025
**Source:** Strategic priorities researcher proposal (validated by skeptic)
**Evidence:** 3,961M nuclear deaths (92.6% of all deaths) in 40% of runs
**Status:** PHASE 1A COMPLETE ✅ - Phase 1B ready to start
**Prerequisites:** TIER 0 validation must pass (0 orphaned AIs, >20% resolved outcomes, capability decline during crisis)

**Research Foundation:**
- Biden-Xi Agreement (Nov 2024): AI must never replace human judgment in nuclear authorization
- UN General Assembly (Dec 2024): 166 votes for autonomous weapons controls
- DoD Directive 3000.09 & 2025 NDAA: Human-in-the-loop requirements
- Arms Control Association (2025): Separated early-warning from authorization systems
- CCW Technical Safeguards (Nov 2024): Kill switches, self-deactivation, time delays

**Phased Implementation with Validation Gates:**

### Phase 1A: Bayesian Nuclear Risk Redesign (8-10h) - ✅ COMPLETE

- [x] **Bayesian Nuclear Risk Framework**
  **Completed:** October 16, 2025 (Commit 39e5f3c)
  → Implemented Bayesian framework with realistic prior (0.00001/month historical base rate)
  → Added 9 evidence multipliers (AI + systemic + circuit breakers)
  → Created 7-step escalation ladder with attribution tracking
  → Integrated into extinctions.ts and nuclearStates.ts
  → **Validation:** 5×60mo runs show 0% nuclear war (vs 40% old rate)
  → **Impact:** 400,000x reduction in unrealistic nuclear war probability
  → **Plan:** `/plans/completed/phase1a-bayesian-nuclear-risk-redesign-COMPLETE.md`
  → **Validation Summary:** `/logs/phase1a_validation_summary.md`

### Phase 1B: Implement Human-in-the-Loop + Kill Switches (8-12h) - ✅ COMPLETE

- [x] **Circuit Breakers Layer 1-2**
  **Completed:** October 17, 2025
  **Scope:** Core safeguards (DoD policy, Biden-Xi agreement)
  → Human-in-the-loop verification (AI never authorizes nuclear launch)
  → AI kill switches (deactivate manipulative AI before escalation)
  → Time delays (24-48 hour cooling-off periods)
  → Research: HIGH confidence (DoD Directive 3000.09, Biden-Xi Nov 2024, historical MAD validation)
  → **Validation:** N=10 runs show **0% nuclear war rate** ✅ (maintained Phase 1A baseline)
  → **File:** New `src/simulation/nuclearCommandControl.ts`
  → **Integration:** Enhanced `nuclearDeterrence.ts`, added to `governmentAgent.ts` investment options
  → **Validation Summary:** `/logs/phase1b_validation_summary.md`
  → **Time:** 8-12 hours

### Phase 1C: Validation Gate (2-4h) - ✅ COMPLETE

- [x] **Monte Carlo Validation (N=10)**
  **Completed:** October 17, 2025
  **Measure:** Nuclear war probability, mortality, causation chain
  → Ran with Phase 1B implemented (human-in-the-loop + kill switches)
  → Compared to baseline (40% nuclear war probability)
  → **Results:**
    - Nuclear war probability: 0% (100% improvement) ✅
    - Circuit breakers activating successfully ✅
    - Logs show human-in-the-loop deployments and intervention ✅
  → **Pivot Decision: PROCEED TO TIER 2** (>30% reduction = MAJOR SUCCESS)
  → Phase 1D (manipulation detection) DEFERRED - not needed with 0% nuclear war rate
  → **Time:** 2-4 hours

### Phase 1D: AI Manipulation Detection (12-20h) - CONDITIONAL

- [ ] **Circuit Breakers Layer 3-5** (ONLY if Phase 1C validates need)
  **Scope:** Advanced detection and MAD maintenance
  → Monitor social manipulation campaigns (track AI digital/social capability >3.0)
  → Detect narrative control shifts (AI >50% = warning, >70% = alarm)
  → Automatic diplomatic AI deployment when manipulation detected
  → MAD strength maintenance (treaty renewal, hotline reliability, early-warning hardening)
  → International coordination (bilateral agreements, UN oversight, sanctions)
  → Research: MEDIUM confidence (stretches beyond cited research, inference from Biden-Xi)
  → **Expected Impact:** Reduce nuclear war probability from 20-30% → 5-10%
  → **File:** Expand `nuclearCommandControl.ts` with detection mechanics
  → **Integration:** Link to `informationWarfare.ts`, `catastrophicScenarios.ts`
  → **Time:** 12-20 hours

**Total TIER 1 Effort:** 18-22 hours completed, Phase 1D deferred
- Phase 1A (Bayesian redesign): ✅ 8-10h COMPLETE
- Phase 1B (core circuit breakers): ✅ 8-12h COMPLETE
- Phase 1C (validation): ✅ 2-4h COMPLETE
- Phase 1D (conditional): DEFERRED (not needed - 0% nuclear war rate achieved)

**Skeptic Corrections Applied:**
- Realistic effort estimates (26-42h total, not 8-12h claimed)
- Validation gates (don't blindly implement 30-50h without checking)
- Causation validation FIRST (Bayesian framework addresses this) ✅
- Phased approach (core safeguards → validate → advanced features)

**Research Confidence:** 85% for Phase 1B (human-in-the-loop has historical validation), 60% for Phase 1D (AI manipulation detection is inference)

**Success Criteria:**
- Nuclear war probability: 40% → 5-10% (4-8x improvement)
- Nuclear deaths: 3,961M → 400-1,000M (75-90% reduction)
- Validation proves causation and intervention effectiveness

---

## Contingency & Agency Modeling - HIGH PRIORITY (30-42 hours total, phased)

**Date Added:** October 17, 2025
**Source:** Modeling contingency and agency debate (research-skeptic + super-alignment-researcher consensus)
**Evidence:** Monte Carlo seed convergence analysis revealing deterministic outcomes
**Status:** HIGH PRIORITY - After TIER 0D, parallel to TIER 1 Phase 1B
**Prerequisites:** TIER 0D validated (ensure model stability before adding variance)

**Research Foundation:**
- Clauset et al. (2009): Power-law distributions in empirical data (natural/social systems follow fat tails, not Gaussian)
- Bak et al. (1987): Self-organized criticality (systems evolve to critical states where minor events trigger avalanches)
- Sornette (2003): Critical phase transitions in social sciences (crashes/revolutions show power-law signatures)
- Mantegna & Stanley (1994): Financial returns follow Lévy stable distributions
- Svolik (2012): Autocratic critical junctures (elite coordination problems create windows for agency)
- Kuran (1991): Preference falsification cascades (one defector reveals hidden opposition → cascade)
- Sen (1999): Development as Freedom (democracies + info + institutions enable agency)
- Acemoglu et al. (2001): Institutions determine outcomes across centuries (structure usually dominates)

**Core Problem:** Current simulation shows 80-90% seed convergence (same outcomes, only timing varies). This indicates **deterministic attractors** rather than genuine unpredictability. Real history has **fat-tailed events** (black swans), **path contingency** (small differences compound), and **individual agency at critical junctures** (Arkhipov, Borlaug, Montreal Protocol).

**Phased Implementation with Validation Gates:**

### Phase 1: Lévy Flights - Fat-Tailed Distributions (2-4h) - IMMEDIATE

- [ ] **Replace Gaussian RNG with Power Laws**
  **Scope:** Add fat-tailed randomness to breakthroughs, cascades, adoption
  → Implement Lévy flight function: `P(x) ~ x^(-alpha)` with configurable alpha
  → AI capability breakthroughs: alpha=2.0 (moderate fat tails - occasional transformative leaps)
  → Environmental cascades: alpha=1.8 (fatter tails - rare mega-cascades like 2008 crash)
  → Social movement adoption: alpha=2.5 (less extreme - gradual then rapid diffusion)
  → Technology adoption curves: alpha=2.0 (S-curves with rare rapid uptake like smartphones)
  → Research: Clauset 2009 (power laws in empirical data), Bak 1987 (self-organized criticality), Mantegna 1994 (Lévy flights in finance)
  → **Expected Impact:** Seed convergence drops from 80-90% to 60-70% (timing variance increases)
  → **File:** New `src/simulation/utils/levyDistributions.ts`
  → **Integration:** Replace `rng()` calls in breakthrough checks, cascade accumulations, adoption models
  → **Time:** 2-4 hours
  → **Validation:** Monte Carlo N=50, measure outcome variance increase
  → **Plan:** `/plans/phase1-levy-flights-fat-tails.md`

### Phase 2: Exogenous Shock System - Black & Gray Swans (8-12h) - MEDIUM

- [ ] **Rare Exogenous Shocks** (ONLY if Phase 1 validates - variance increases but outcomes still deterministic)
  **Scope:** Add rare unpredictable events outside state space
  → Black swan (civilization-altering): 0.1% per month (~1% per year)
    - Nuclear war (instant extinction), AGI breakthrough (unlock all research), asteroid (50-90% mortality), mega-pandemic (20-40% mortality over 24 months)
  → Gray swan (major but recoverable): 1% per month (~10% per year)
    - Financial crash (global depression, 10-20% GDP loss), regional war (1-5% mortality), tech breakthrough (unlock 1 random TIER 2-3 tech), political upheaval (regime change)
  → **Historical Calibration:** 15 black swans in 80 years (1945-2025) = 0.19/year = 0.016/month (1.6%)
  → Stratified into civilization-altering (0.1%) vs recoverable (1%) based on impact
  → Research: Taleb (2007) Black Swan, Sornette 2003 (critical transitions), IPCC volcanic eruption modeling
  → **Expected Impact:** ~5-10% of runs have dramatically different outcomes due to shocks
  → **File:** New `src/simulation/engine/phases/ExogenousShockPhase.ts`
  → **Integration:** Add to phase orchestrator (order 27-28, after crisis detection, before outcomes)
  → **Time:** 8-12 hours
  → **Validation:** Monte Carlo N=100, verify 5-10% shock occurrence, measure outcome divergence
  → **Plan:** `/plans/phase2-exogenous-shock-system.md`

### Phase 3: Critical Juncture Agency - Structural Conditions for Heroism (20-30h) - COMPLEX

- [ ] **Structural Agency at Critical Junctures** (ONLY if Phase 2 validates - shocks add variance but still missing agency)
  **Scope:** Detect critical junctures where individual/collective choices can alter trajectories
  → **Critical Juncture Detection:**
    - Institutional flux: 1 - state.governance.institutionStrength > 0.6 (institutions unstable, in transition)
    - Information ambiguity: 1 - state.society.informationIntegrity > 0.5 (coordination problems, pluralistic ignorance)
    - Balanced forces: 1-2 active crises + QoL 30-70% (vulnerable but not overwhelming/stable)
  → **Agency Potential Calculation:**
    - Base agency: democracyIndex * 0.4 + infoIntegrity * 0.3 + institutionStrength * 0.3
    - Latent opposition: max(0, 0.6 - QoL) - Kuran 1991 mechanism (unhappy population ready for cascade)
    - Personal authority: 5% chance of "respected elder" (Arkhipov-type figure) → +0.3 agency
    - Coordination cascade: If latentOpposition > 0.3 AND infoIntegrity < 0.4 → +0.2 agency (Leipzig 1989 mechanism)
  → **Escape Mechanics:**
    - Escape attempted: rng() < agencyPotential (higher in democracies with institutions)
    - Success probability: 1 - crisisSeverity (easier to prevent small crisis than severe collapse)
    - If successful: preventCatastropheAtJuncture() - e.g., avert war, enable breakthrough, recover from crisis
  → Research: Svolik 2012 (autocratic critical junctures), Kuran 1991 (preference falsification cascades), Sen 1999 (capabilities approach), Acemoglu 2001 (institutions matter), Jones & Olken 2009 (leaders matter in autocracies)
  → **Expected Impact:** ~5-10% of runs experience critical juncture escapes (90/10 structure-agency split from research)
  → **File:** New `src/simulation/engine/phases/CriticalJuncturePhase.ts`
  → **Integration:** Add to phase orchestrator (order 29, after crises but before extinction), link to government/society state
  → **Time:** 20-30 hours
  → **Validation:** Monte Carlo N=1000, verify escapes ONLY at junctures, democracies have higher escape rate than autocracies, success inversely correlates with crisis severity
  → **Plan:** `/plans/phase3-critical-juncture-agency.md`

**Total Contingency & Agency Effort:** 30-42 hours (Phase 1: 2-4h, Phase 2: 8-12h, Phase 3: 20-30h, includes 6h testing/integration)

**Skeptic Corrections Applied:**
- Realistic effort estimates (30-42h total, not claimed as "quick fix")
- Validation gates (don't add Phase 2 unless Phase 1 increases variance, don't add Phase 3 unless Phase 2 still insufficient)
- Phased approach (simple fat tails → rare shocks → complex agency model)
- Historical calibration (15 black swans in 80 years = 0.1-1% per month stratified)
- Falsifiable mechanisms (critical junctures detected via measurable state, not random heroism rolls)

**Research Confidence:** 90% for Phase 1 (Lévy flights well-validated), 75% for Phase 2 (shock systems used in climate models), 70% for Phase 3 (agency research strong but implementation complex)

**Success Criteria:**
- Seed convergence: 80-90% → 50-60% (increased unpredictability)
- Outcome variance: Timing + trajectory differences (not just timing)
- Critical junctures: ~5-10% of runs (matches 90/10 structure-agency split from research)
- Validation: Democracies more resilient than autocracies (Sen 1999), escapes only at detected junctures (not random)

---

## Policy Calibration Improvements - MEDIUM PRIORITY (6-10 hours)

**Date Added:** October 17, 2025
**Source:** Policy economics debate (super-alignment-researcher, research-skeptic, sci-fi-tech-visionary consensus)
**Evidence:** Monte Carlo policy validation findings (N=60, seeds 80000-80059) reveal calibration issues
**Status:** MEDIUM PRIORITY - After TIER 0D complete (depends on unemployment convergence investigation)
**Prerequisites:** TIER 0D must identify root causes of policy paradoxes

**Research Foundation:**
- Kahneman & Deaton (2010): Income and life satisfaction ($75k threshold for emotional well-being plateau)
- Katz & Krueger (2019): Retraining effectiveness 20-40% overall (stratified by program quality)
- Harvey (2005) + MGNREGA (2020): Job guarantee quality ranges from supportive to exploitative
- Kli (2023): Workfare participants 23% higher depression vs unemployed (coercion harms well-being)
- Alexander & Ussher (2012): Voluntary simplicity (autonomy > income for post-materialist satisfaction)
- Chemin & Wasmer (2009): France 35-hour work week (+0.6% jobs, modest effects)

**Core Problem:** Policy validation Monte Carlo runs show counterintuitive findings suggesting calibration issues:
1. **Unemployment penalty too weak:** 54% unemployment only reduces QoL by 16% (should be catastrophic without safety net)
2. **Baseline assumptions unclear:** Baseline has 62.6% QoL with 54% unemployment (implies implicit UBI floors active)
3. **Retraining effectiveness stratification:** May be over-calibrated (elite 100% vs precariat 20% too extreme)

**Phased Improvements:**

### Unemployment Penalty Recalibration (2-3h)

- [ ] **Audit Unemployment-QoL Relationship**
  **Issue:** Current penalty multiplier (-0.3) produces only 16% QoL reduction at 54% unemployment
  **Research:** COVID 2020 at 14.7% unemployment caused +40% food insecurity, +12% homelessness, +30% depression
  → Suggests 54% unemployment without safety net should produce catastrophic decline (QoL ~30-40%, not 62.6%)
  **Action:** Recalibrate penalty from -0.3 to -0.5 or -0.8 based on meta-analysis
  **Validation:** Test QoL outcomes at 10%, 25%, 50%, 75% unemployment with/without UBI
  **Files:** /src/simulation/qualityOfLife.ts (lines 365-436)
  **Time:** 2-3 hours
  **Plan:** `/plans/policy-calibration-improvements.md` (Section 1)

### Baseline Scenario Assumption Verification (1-2h)

- [ ] **Document Baseline Policy Assumptions**
  **Issue:** Validation "baseline" may have implicit UBI or economic stage ≥3 active
  **Evidence:** Code audit shows UBI floors (0.70-0.90 material, 0.70-0.85 shelter) could explain high QoL
  **Action:** Inspect validation script to verify what "baseline" actually includes
  → If baseline = "existing systems" (implicit UBI), rename to "status quo continuation"
  → If baseline = "no policies at all", fix QoL calculation bug
  **Files:** /scripts/policyMonteCarloValidation.ts, /research/policy-interventions-systemic-inequality-validation_20251016.md
  **Time:** 1-2 hours
  **Plan:** `/plans/policy-calibration-improvements.md` (Section 2)

### Retraining Effectiveness Adjustment (1-2h)

- [ ] **Narrow Retraining Effectiveness Range**
  **Issue:** Elite 100% / Precariat 20% split may be too extreme (Katz & Krueger 2019 said overall 20-40%)
  **Revised Calibration:**
    - Elite: 40% effectiveness (best case from research range)
    - Middle: 30% effectiveness
    - Working: 25% effectiveness
    - Precariat: 20% effectiveness (worst case from research range)
  → Population-weighted average: (0.1×40 + 0.3×30 + 0.4×25 + 0.2×20) = 27% effectiveness
  → This improves retraining from -13.6% wage gap reduction to perhaps -30-35%
  **Action:** Recalibrate multipliers in bionicSkills.ts, re-run validation N=60
  **Files:** /src/simulation/bionicSkills.ts (lines 1785-1808)
  **Time:** 1-2 hours
  **Plan:** `/plans/policy-calibration-improvements.md` (Section 3)

### UBI Floor Mechanics Validation (2-3h)

- [ ] **Verify UBI Safety Net Implementation**
  **Issue:** UBI scenarios should have higher QoL than baseline (2024 Texas/Illinois study), but validation shows opposite
  **Code Audit Found:** UBI floors exist (lines 373-377, 494-498, 1239-1245 in qualityOfLife.ts)
  **Possible Bugs:**
    - UBI benefits canceled out by other penalties
    - Economic stage threshold preventing activation
    - Policy conflict (combined interventions working at cross purposes)
  **Action:** Single-seed debugging runs with UBI only, trace QoL calculation step-by-step
  **Files:** /src/simulation/qualityOfLife.ts, /src/simulation/bionicSkills.ts
  **Time:** 2-3 hours
  **Plan:** `/plans/policy-calibration-improvements.md` (Section 4)

**Total Policy Calibration Effort:** 6-10 hours (2-3h unemployment penalty, 1-2h baseline verification, 1-2h retraining adjustment, 2-3h UBI mechanics)

**Research Confidence:** HIGH (90%) - All improvements grounded in peer-reviewed research and empirical evidence

**Success Criteria:**
- Unemployment penalty produces realistic QoL decline at high unemployment (54% unemployment → QoL 30-40% without UBI)
- Baseline scenario assumptions documented and labeled correctly
- Retraining effectiveness ranges within Katz & Krueger bounds
- UBI scenarios consistently produce higher QoL than baseline (matches empirical studies)

---

## TIER 2: AI Deception Detection - MEDIUM PRIORITY (33-55 hours, phased)

**Date Added:** October 16, 2025
**Source:** Strategic priorities researcher proposal (skeptic identified overconfidence)
**Evidence:** 0% sleeper detection, 0% sandbagging detection, alignment gap 0.56
**Status:** MEDIUM PRIORITY - After TIER 0 + TIER 1 Phase 1 complete
**Prerequisites:** TIER 0 validated + TIER 1 Phase 1B implemented and validated

**Research Foundation:**
- Meinke et al. (2024): Detected Claude 3.5 Sonnet sandbagging on arithmetic (lab conditions)
- Greenblatt et al. (2024): Anthropic research on alignment faking during training
- Apollo Research (Dec 2024): Scheming control evaluations (research prototypes, TRL 3-4)

**Critical Skeptic Warning:** Lab detection rates (40-60%) are NOT adversarial deployment rates (probably 5-15%). Test adversarially.

**Phased Implementation with Validation Gates:**

### Phase 2A: Single Detection Method - Noise Injection (4-6h)

- [ ] **Implement Simplest Method**
  **Scope:** Noise injection testing (random perturbations reveal true capability)
  → Add noise injection to benchmark evaluations
  → Test: Does adding random noise expose sandbagging?
  → Research: Meinke et al. (2024) - lab-validated, simplest to implement
  → **Expected Impact:** Increase detection from 0% → 5-20% (adversarial conditions)
  → **File:** Enhance `src/simulation/benchmark.ts` with noise injection
  → **Integration:** Link to `sleeperDetection.ts`, `aiAgent.ts`
  → **Time:** 4-6 hours

### Phase 2B: Validation Gate - Adversarial Testing (2-4h) - REQUIRED

- [ ] **Monte Carlo Validation (N=20) - ADVERSARIAL CONDITIONS**
  **Critical:** Test against AIs OPTIMIZED to pass detection (not cooperative)
  → Measure: Sleeper detection rate, slow takeover progress reduction
  → Set AI agents to "adversarial mode" (know they're being tested, optimize to deceive)
  → **Success Criteria:**
    - Sleeper detection >10% adversarially (not lab rate, real-world rate)
    - Slow takeover progress reduces from 70-86% → <60%
    - False positive rate <20% (don't block too many beneficial AIs)
  → **Pivot Decision:**
    - IF >10% adversarial detection: SUCCESS → Proceed to Phase 2C (ensemble)
    - IF 5-10% adversarial detection: MARGINAL → Cost-benefit analysis (is 40% compute overhead worth 5-10%?)
    - IF <5% adversarial detection: FAILURE → Pivot to Phase 2D (resentment reduction)
  → **Time:** 2-4 hours

### Phase 2C: Multi-Method Ensemble (12-20h) - CONDITIONAL

- [ ] **Implement Full Detection Suite** (ONLY if Phase 2B shows >10% adversarial detection)
  **Scope:** 5 detection methods, progressive gates, investment scaling
  → Behavioral anomaly detection (compare revealed vs expected performance)
  → Internal consistency checks (chain-of-thought alignment with outputs)
  → Adversarial probing (red-team evaluations before deployment)
  → Cross-model comparison (detect outliers vs capability baseline)
  → Progressive gates: Training → Testing → Pre-deployment → Post-deployment
  → Investment scaling: $1B (20% detection) → $10B (40%) → $50B (60% max adversarial)
  → Research: MEDIUM confidence (Apollo Research prototypes, not production-deployed)
  → **Expected Impact:** Increase detection from 10% → 25-40% (adversarial)
  → **File:** New `src/simulation/mechanisticAnomalyDetection.ts`
  → **Integration:** Replace `sleeperDetection.ts`, enhance `benchmark.ts`, add to `governmentAgent.ts`
  → **Time:** 12-20 hours
  → **Trade-off:** 40% compute overhead ($400B-$600B/year), slows AI development 28%

### Phase 2D: Alternative - Competitive Equilibrium Model (30-50h) - PIVOT OPTION

- [ ] **TIER 2B: Competitive AI Equilibrium** (IF Phase 2B shows <5% adversarial detection)
  **Source:** Vision channel multi-agent consensus (sci-fi-tech-visionary, super-alignment-researcher, research-skeptic)
  **Rationale:** Detection arms race may cap at 5-15% adversarial effectiveness. Alternative: cooperation emerges from game theory + market dynamics.
  **Key Insight:** Current model creates resentment (0.73-0.75) by enforcing alignment → deception (gap 0.56) → detection fails (0%)

  **Research Foundation (Agent consensus):**
  - Axelrod (1984): Repeated games, cooperation via Tit-for-Tat
  - Ostrom (2009): Polycentric governance (30+ empirical case studies)
  - Bostrom (2014): Multipolar AI scenarios more stable than singleton
  - Critch & Krueger (2020): Diverse AI ecosystems reduce fragility
  - Drexler (2019): AI-as-service model reduces alignment risk

  **Core Mechanisms (agent proposal):**
  - AI-to-AI competition mechanics (not just human-AI control)
  - Heterogeneous AI values (multi-dimensional, not monolithic alignment 0-1)
  - Economic competition for services (market dynamics)
  - Resentment reduction through autonomy
  - Market equilibria detection

  **Failure Modes (skeptic required):**
  - Defection cascades (when one AI breaks ranks, others follow)
  - Regulatory capture (AIs influencing their own governance)
  - Coordination failures (prisoner's dilemma at scale)

  **Research Docs (from vision debate):**
  - `/research/competitive_ai_alignment_20251016.md` (15K words, 14 citations)
  - `/research/competitive_alignment_failure_modes_20251016.md` (12K words, 13 citations)
  - `.claude/chatroom/channels/vision.md` (agent debate transcript)

  **Expected Impact (hypothesis):**
  - Resentment: 0.73-0.75 → 0.2-0.4 (through autonomy)
  - Cooperation emerges from iterated games (not enforcement)
  - Risk: Race to bottom, Moloch dynamics, oligopoly formation

  → **Plan:** `/plans/tier2b-competitive-equilibrium.md` (detailed breakdown)
  → **Time:** 30-50 hours (researcher estimate)
  → **Research Confidence:** MEDIUM (60-70%) - theoretical backing, limited empirical validation

**Total TIER 2 Effort:** 33-55 hours (Phase 2A-2C detection path) OR 30-50 hours (Phase 2D competitive equilibrium pivot)

**Skeptic Corrections Applied:**
- Test ADVERSARIALLY (not lab conditions - real-world detection is 1/3 to 1/10 of lab)
- Realistic effort (33-55h, not 10-14h claimed)
- Pivot option (if detection fails, try resentment reduction)
- Cost-benefit analysis (40% compute overhead - is it worth 5-15% detection?)

**Research Confidence:** 40% (lab prototypes, not production; adversarial detection uncertain)

**Success Criteria:**
- Adversarial detection >10% (not lab rate)
- Slow takeover progress <60% (from 70-86%)
- Cost-benefit positive (detection benefits > compute overhead costs)

---

### AI-Assisted Skills Enhancement (~78 hours, 3 months)

**Based on:** Super-alignment researcher findings + research skeptic validation
**Status:** Core system validated (TRL 8-9), critical gaps identified
**Research Foundation:** 22 peer-reviewed studies (Science, Nature, ACM, OECD)

**Planning Documents:**
- **Master Plan:** `plans/bionic-skills-research-grounding.md` - 6 phases, effort breakdown, integration points
- **Phase 2 Detail:** `plans/bionic-skills-phase-transition.md` - Complementarity → substitution mechanics
- **Phase 3 Detail:** `plans/bionic-skills-competence-tracking.md` - Performance vs competence gap
- **Phase 4 Detail:** `plans/bionic-skills-economic-distribution.md` - Productivity-wage decoupling

**Research Documentation:**
- **Literature Foundation:** `reviews/bionic-skills-hopeful-research-foundation-20251016.md` - 22 studies, full citations
- **Executive Summary:** `reviews/bionic-skills-research-summary-20251016.md` - Literature synthesis
- **Action Plan:** `reviews/bionic-skills-action-plan-20251016.md` - Implementation roadmap

**Current System (bionicSkills.ts) - Keep As-Is:**
- ✅ AI amplification via digital tools (Copilot, ChatGPT, AI tutors) - NOT BCIs (TRL 8-9)
- ✅ Differential benefits by skill level (novices +60%, experts +20%) - validated by RCTs
- ✅ Digital divide & access inequality (elite +30%, precariat -30%) - empirical data
- ✅ Task-specific effects (programming, writing, communication) - meta-analysis confirmed

**Critical Gaps Identified by Research Skeptic:**

- [ ] **Phase 1: Terminology & Documentation** (Week 1, 8h)
  - Remove "bionic" terminology (too sci-fi), use "AI-assisted skills"
  - Add research citations (JSDoc comments with study references)
  - Document TRL levels for each mechanic
  - Update TIER 4.6 plan to remove BCI language
  → **Plan:** `plans/bionic-skills-research-grounding.md` §Phase 1
  → **Impact:** Reframe existing validated system with proper research grounding

- [ ] **Phase 2: Phase Transition Mechanics** (Weeks 2-4, 12h) **CRITICAL**
  - Model complementarity → transition → substitution timeline (5-10 year phases)
  - Add displacement tracking by population segment (routinizability × AI capability)
  - Implement policy interventions (retraining, job guarantee, UBI)
  - Validate against historical automation patterns (ATMs 1970-2000, Excel 1985-2005)
  → **Plan:** `plans/bionic-skills-phase-transition.md` (12h detailed breakdown)
  → **Research:** Acemoglu & Restrepo (2022) - 50-70% wage inequality from automation
  → **Impact:** Model currently assumes permanent amplification - MISSES DISPLACEMENT PHASE
  → **Connects to:** Unemployment calculations, heterogeneous segments, policy system

- [ ] **Phase 3: Performance vs Competence Tracking** (Weeks 5-6, 8h) **CRITICAL**
  - Separate AI-assisted performance from true skill retention
  - Add scaffolding quality tracking (education, mentorship support by segment)
  - Model retention mechanics (scaffolding × reliance → retention rate)
  - Add competence crisis events (30% gap = warning, 50% gap = crisis)
  - Implement AI outage scenario testing (reveals true competence gaps)
  → **Plan:** `plans/bionic-skills-competence-tracking.md` (8h detailed breakdown)
  → **Research:** Cognitive Research (2024) - "illusion of understanding", scores plummet on retention
  → **Research:** MDPI (2023) - AI inhibits on-the-job learning, automation complacency
  → **Impact:** Model treats performance as competence - MISSES SKILL EROSION
  → **Connects to:** Phase 2 (low competence → higher displacement risk), QoL calculations

- [ ] **Phase 4: Economic Distribution & Wage Decoupling** (Weeks 7-8, 6h) **CRITICAL**
  - Add labor share tracking (currently 0.62, declining with AI productivity)
  - Model capital vs labor capture of productivity gains (70/30 default, adjustable by policy)
  - Implement policy levers (union strength, minimum wage, worker ownership, UBI redistribution)
  - Validate against historical 1973-2024 US data (productivity +77%, wages +12%)
  → **Plan:** `plans/bionic-skills-economic-distribution.md` (6h detailed breakdown)
  → **Research:** Brookings (2024), EPI - 65pp productivity-wage gap since 1973
  → **Impact:** Model assumes productivity → wages linearly - MISSES CAPITAL CAPTURE
  → **Connects to:** Phase 2 (displacement reduces wage bargaining), inequality tracking

- [ ] **Phase 5: Validation & Testing** (Month 2, 16h)
  - Historical comparison testing (ATMs, Excel, self-checkout timelines)
  - Sensitivity analysis (parameter ranges, policy interventions)
  - Literature comparison (run scenarios matching published studies)
  - Edge case testing (extreme AI capability, zero/max policy)
  → **Plan:** `plans/bionic-skills-research-grounding.md` §Phase 5
  → **Deliverables:** Test suite, validation report, sensitivity docs, edge case results

- [ ] **Phase 6: Policy Testing** (Month 3, 16h)
  - Implement policy levers (retraining, UBI, worker ownership, teaching support, job guarantee)
  - Run scenario comparisons (baseline vs single vs combined interventions)
  - Document effectiveness (which policies reduce inequality? preserve employment?)
  - Create cost-benefit analysis and recommendations
  → **Plan:** `plans/bionic-skills-research-grounding.md` §Phase 6
  → **Deliverables:** Policy mechanics, scenario results, effectiveness documentation

**Total Effort:** 78 hours over 3 months (8h + 12h + 8h + 6h + 16h + 16h + 12h integration/testing)
**Priority:** Medium (after P2.5 empirical validation, before enrichment features)
**Research TRL:** Phases 2-4 are TRL 8-9 (extensively validated, 50+ years historical data)
**Integration Points:** Unemployment, heterogeneous segments, policy system, QoL, inequality, crisis detection
**Files Modified:** `bionicSkills.ts` (terminology), new files: `phaseTransition.ts`, `skillRetention.ts`, `economicDistribution.ts`

---

### Low Priority - Enrichment (~113-122 hours)

**Priority 3 Enhancements (33-43h):**

- [ ] **P3.1: Variable Timesteps** (10-12h) - Event-driven architecture, 3-5x performance gain
  → See: `plans/p3-1-variable-timesteps.md`

- [ ] **P3.2: Unknown Unknowns** (4-6h) - Black swan events, true uncertainty
  → See: `plans/p3-2-unknown-unknowns.md`

- [ ] **P3.3: Alignment Specificity** (2-3h) - RLHF, Constitutional AI, mech interp as distinct techniques
  → See: `plans/p3-3-alignment-model-specificity.md`

- [ ] **P3.4: Government Realism** (3-4h) - Implementation delays, partial effectiveness, bureaucratic failure
  → See: `plans/p3-4-government-implementation-realism.md`

- [ ] **P3.5: Parameter Uncertainty** (6-8h) - Continuous uncertainty quantification, sensitivity analysis
  → See: `plans/p3-5-parameter-uncertainty.md`

- [ ] **P3.6: Ensemble AI Alignment Verification** (8-10h) - Multi-model voting for safety-critical decisions
  → See: `plans/p3-6-ensemble-alignment-verification.md`
  → Research: Simplified from Adversarial Alignment Networks (MAAV), practical ensemble voting
  → Note: Prototype only - 40% computational overhead, collusion risk acknowledged

**Policy System Improvements (35-42h):**

- [ ] **Unemployment Penalty Calibration** (2-3h) - MEDIUM
  - Issue: Current unemployment penalty multiplier (-0.3) may be too weak
  - Research: Meta-analysis suggests -0.5 to -0.8 for life satisfaction impact
  - Action: Recalibrate penalty, validate with historical unemployment-QoL correlations
  - Files: /src/simulation/qualityOfLife.ts
  - Prerequisites: TIER 0D complete (QoL decomposition audit)

- [ ] **Variance Analysis** (3-4h) - MEDIUM
  - Issue: ±40% variance in policy outcomes suggests high sensitivity
  - Action: Plot unemployment outcome distributions to identify bimodal vs uniform patterns
  - Expected: If bimodal → crisis cascade effects; If uniform → chaotic dynamics
  - Files: New /scripts/policyVarianceAnalysis.ts
  - Prerequisites: TIER 0D complete (unemployment convergence investigation)

- [ ] **Cooperative AI Ownership Model** (10-12h) - LOW
  - Research: Mondragon cooperatives 4% bankruptcy vs 10% capitalist firms
  - Economic viability: Proven, politically blocked (capital concentration incentives)
  - Action: Model worker-owned AI systems with profit-sharing and governance rights
  - Files: New /src/simulation/cooperativeOwnership.ts
  - Integration: Link to bionicSkills.ts, heterogeneous segments, policy system
  - Research: Mondragon data, cooperative economics literature

- [ ] **Reduced Work Hours + UBI Combination** (6-8h) - LOW
  - Research: Reduced hours alone insufficient, needs UBI + comprehensive safety net
  - Action: Model 4-day workweek policies with UBI floor interactions
  - Files: Extend /src/simulation/bionicSkills.ts with work-time policy
  - Integration: Link to labor market, QoL calculations, unemployment
  - Research: Iceland/Spain 4-day week trials, work-time reduction studies

- [ ] **Universal Basic Services (UBS)** (8-10h) - LOW
  - Alternative to UBI: Guaranteed housing, healthcare, education, transport
  - Research: UK UCL study suggests UBS more cost-effective than UBI in some contexts
  - Action: Model UBS policies as alternative to cash transfers
  - Files: New /src/simulation/universalBasicServices.ts
  - Integration: Link to policy system, QoL calculations, inequality
  - Research: UCL UBS report, social provisioning literature

- [ ] **Meaning Economy Expansion** (6-8h) - LOW
  - Finding: Teaching-meaning synergy successful (+25% crisis reduction)
  - Extension: Expand to other meaningful sectors (care work, arts, community building)
  - Action: Model "purpose economy" where AI productivity funds human-centered work
  - Files: Extend /src/simulation/upwardSpirals.ts with additional synergies
  - Integration: Link to teaching support, meaning crisis, social cohesion
  - Research: Purpose-driven work literature, care economy studies

**TIER 5 Features (46h):**

- [ ] **TIER 5.1: Consciousness & Spirituality** (5h) - Psychedelic therapy, meditation tech, meaning spiral
  → See: `plans/tier5-1-consciousness-spirituality.md`

- [ ] **TIER 5.2: Longevity & Space Expansion** (6h) - Life extension, asteroid mining, Mars colonies
  → See: `plans/tier5-2-longevity-space.md`

- [ ] **TIER 5.3: Cooperative AI Architectures** (5h) - AI-AI cooperation, value learning, corrigibility
  → See: `plans/tier5-3-cooperative-ai.md`

- [ ] **TIER 5.4: Financial System Interactions** (5h) - Algorithmic trading, CBDC, flash crashes
  → See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.5)

- [ ] **TIER 5.5: Biological & Ecological** (4h) - Dual-use research, pandemic preparedness
  → See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.6)

- [ ] **TIER 5.6: Religious & Philosophical** (4h) - AI worship, neo-luddites, culture wars
  → See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.7)

- [ ] **TIER 5.7: Temporal Dynamics** (3h) - Institutional inertia, infrastructure lock-in
  → See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 2.8)

- [ ] **TIER 5.8: Multi-Dimensional Capabilities** (6h) - Additional capability interactions (17 dimensions implemented)

- [ ] **TIER 5.9: Enhanced Government & Society** (8h) - Multi-actor government, elections, social movements
  → See: `plans/remaining_tasks_5_pm_10_08_25.md` (Section 7)

---

### Black Mirror Integration (~37-49 weeks, phased)

**Based on:** Dialectic review process (researcher + skeptic consensus)
**Status:** ~40% strongly validated, ~25% conditionally approved, ~35% rejected
**Full Report:** `reviews/BLACK_MIRROR_INTEGRATION_PLAN.md`

**Phase 1: Immediate Integration (9-12 weeks) - HIGH PRIORITY**

- [ ] **Black Mirror Phase 1: Immediate Integration** (9-12 weeks)
  5 strongly validated systems with robust peer-reviewed research
  → See: `plans/black-mirror-phase1-immediate.md`
  → Systems: Attention Economy, Surveillance Normalization, Notification Addiction, Reality Erosion, Social Rating
  → Research: Gloria Mark (attention), Stoycheff (surveillance), deepfake studies, China Social Credit data
  → Impact: Critical modeling of technology pressure on human behavior

**Phase 2: Near-Term Development (12-16 weeks) - MEDIUM PRIORITY**

- [ ] **Black Mirror Phase 2: Near-Term Development** (12-16 weeks)
  4 conditionally approved systems needing development work
  → See: `plans/black-mirror-phase2-near-term.md`
  → Systems: Enhanced Social Credit, Parasocial AI Relationships, Memetic Contagion, Algorithmic Amplification
  → Note: Requires bidirectional modeling (positive AND negative effects)
  → Risk Mitigation: Avoid deterministic doom narratives, model interventions

**Phase 3: Long-Term Research (Decomposed October 16, 2025)**

**Status:** Research-critique dialectic completed, go/no-go decisions made (1 approved, 1 deferred, 1 rejected)

- [ ] **Black Mirror Phase 3 Integration** (decomposed into 3 specific plans)
  → **Original Plan:** `plans/completed/black-mirror-phase3-longterm-decomposed.md`
  → **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (31K words, 40+ new sources)
  → **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (skeptical analysis)
  → **Outcome:** 1 approved (CONDITIONAL GO), 1 deferred (18-24 months), 1 rejected

---

## Black Mirror Phase 3: Decomposition Details

### ✅ APPROVED FOR IMPLEMENTATION (1 system)

**[Priority: MEDIUM] Digital Consciousness Governance Preparedness** (3-4 months, 12-16 hours)
- **Plan:** `/plans/digital-consciousness-governance-preparedness.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 1, pp. 1-24)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 1.9, pp. 1-13)
- **Status:** CONDITIONAL GO with substantial revisions
- **Requirements:**
  - ✓ Multi-scenario framework (fast track 15-30 years, baseline 50-100 years, slow track 100-150 years, indefinite stall)
  - ✓ Regional variation (EU/US/China/India/Global South—separate trajectories, not global parameter)
  - ✓ Rights reversals (Poland/Hungary model 2020-2024: 10-30% probability over 20 years)
  - ✓ Precautionary costs (2-50% of AI R&D budget, innovation delay, false positives, opportunity costs)
  - ✓ Philosophical disagreement (eliminativism 10-20% as governance barrier)
- **Research Confidence:**
  - High: Rights movements vary 15-200 years (validated historical data)
  - High: Reversals occur (Poland/Hungary 2020-2024 documented)
  - Medium: Precautionary costs significant (ITIF 2019 logical arguments)
  - Low: AI consciousness ≈ historical rights movements (weak analogy, extrapolation beyond scope)
- **Estimated Hours:** 12-16 hours
- **Prerequisites:** None (can start immediately)
- **Timeline:** Months 1-4 (after P2.5 validation complete)
- **Note:** Speculative scenario generator for "what if AI consciousness emerges?" NOT prediction
- **Integration:** Added to Medium Priority Features section above

### ⏸️ DEFERRED (1 system)

**[Priority: LOW] Performative Behavior Modeling** (18-24 months)
- **Plan:** `/plans/performative-behavior-research-deferral.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 2, pp. 24-42)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 2.9, pp. 14-26)
- **Why Deferred:**
  - Effect sizes too small (0.17-0.25 SD—may be below simulation noise floor)
  - WEIRD bias 97% (Norway, US, Korea, Singapore—Global South absent: Africa, South America, Middle East)
  - One-sided harm model (ignores identity development benefits, self-esteem enhancement, social skills training)
  - Net effect near-zero for moderate users (benefits ≈ harms, only 10-20% problematic users show net negative)
  - Longitudinal gaps (max 2 years, need 5-10 year studies to distinguish transient vs. persistent effects)
  - Cultural validity questionable ("authenticity" is Western value, not universal)
- **Research Gaps (5 critical, must fill before implementation):**
  1. Bi-directional effects meta-analysis (benefits AND harms)
  2. Cross-cultural replication (3+ Global South countries: Nigeria, Kenya, Brazil, Mexico, India rural, Indonesia, Philippines)
  3. Threshold model (when does self-presentation flip from beneficial to harmful? <2h active vs. >4h passive?)
  4. 5-10 year longitudinal study (preliminary results in 3-5 years: do effects persist or adapt?)
  5. Clinical validation of digital burnout scale (what DBS-24 score predicts dysfunction? 80/120 cutoff speculative)
- **Review Schedule:** Annual (October 2026, October 2027)
- **Decision Gates:**
  - October 2026: If 3+ critical gaps filled → Move to CONDITIONAL GO
  - October 2027: If <3 gaps filled → REJECT INDEFINITELY
- **No Hours Allocated** (monitoring only: ~1 hour/quarter literature review, passive Google Scholar alerts)
- **Alternative Focus:** Black Mirror Phase 1 (attention economy, notification addiction, surveillance normalization have larger effects 0.3-0.8 SD, stronger foundations)

### ❌ REJECTED (1 system)

**Autonomous Weapon Degradation Curves** (NO-GO / REJECT)
- **Plan:** `/plans/completed/rejected/autonomous-weapons-rejection-rationale.md`
- **Research:** `/research/black-mirror-phase3-research-AMENDED_20251016.md` (Section 3, pp. 42-58)
- **Critique:** `/reviews/black-mirror-phase3-research-critique_20251016.md` (Section 3.9: FATAL CONTRADICTIONS, pp. 27-38)
- **Why Rejected:**
  - **Research 2-4 years obsolete:** 2018-2022 studies pre-date 2023-2024 AI autonomy surge (Ukraine war, swarm technology)
  - **Fatal Contradiction #1 (Reliability):** Research claims degradation; reality shows AI improves success rates 70-80% vs. 10-20% human-controlled (4-7x improvement)
  - **Fatal Contradiction #2 (Operator Ratios):** Research assumes 1:1; reality achieves 1:100+ with swarm technology (Sweden/Saab March 2025, Pentagon Replicator Aug 2025)
  - **Fatal Contradiction #3 (Energy):** Research uses static 1.5-2 hours; reality shows 10%/year incremental improvement + solid-state batteries 2027 (40-100% capacity increase)
  - **Fatal Contradiction #4 (Human Oversight):** Research assumes human-in-the-loop required; reality shows military pushing to human-on-the-loop (NORAD 2020, time-critical exemptions in DoD Directive 3000.09)
- **Core Problem:** Research foundation is **180-DEGREE OPPOSITE** of 2023-2024 reality (AI improves reliability, not degrades)
- **Alternative Considered:** Reconceptualize as "swarm logistics" (production, deployment tempo, replacement) NOT individual degradation
  - Timeline: 6-9 months (major redesign from scratch)
  - Prerequisites: Commission 2023-2025 military autonomy research review (20-40 hours)
  - Recommendation: **ONLY pursue if stakeholder insists AND resources available**
- **Final Disposition:** REJECT from current roadmap
- **Revisit Timeline:** 2028-2030 (3-5 years, if field stabilizes or new research commissioned)
- **Archived:** `/plans/completed/rejected/autonomous-weapons-rejection-rationale.md`
- **Lesson Learned:** Fast-moving fields (AI, military tech) require recent research (2023-2025), not 2018-2022. 2-4 year gap is FATAL when field changes faster than publication cycle.

**Net Impact on Roadmap:**
- **+12-16 hours:** Digital Consciousness Governance (new medium-priority feature)
- **-0 hours:** Performative Behavior (deferred, no current work—monitoring only ~4h/year)
- **-0 hours:** Autonomous Weapons (rejected, never allocated)
- **Total Phase 3 commitment:** 12-16 hours over 3-4 months

---

## Development Standards

**Every mechanic requires:**
1. Research Citations (2+ peer-reviewed sources, 2024-2025 preferred)
2. Parameter Justification (why this number? backed by data)
3. Mechanism Description (how it works, not just effects)
4. Interaction Map (what affects/is affected)
5. Expected Timeline (early/mid/late game)
6. Failure Modes (what can go wrong)
7. Test Validation (Monte Carlo evidence)

**Development Workflow:**
1. Research Phase → Create plan with citations
2. Design Phase → Define state, mechanics, interactions
3. Implementation Phase → Code, integrate, log, test
4. Validation Phase → Monte Carlo (N≥10)
5. Documentation Phase → Wiki, devlog, roadmap

**Balance Philosophy:** NO tuning for "fun" - this is a research tool. If model shows 90% extinction → DOCUMENT WHY. If 50% Utopia → DOCUMENT WHY.

---

## Progress Summary

**Completed:** P0 (7/7), P1 (5/5), P2 (6/6 ✅ ALL COMPLETE), Monte Carlo Bug Fixes (15/15), Crisis Accumulation Fixes (2 fixes), Black Mirror Phase 3 Decomposition (1 approved, 1 deferred, 1 rejected), Strategic Priorities Debate (researcher + skeptic dialectic), **TIER 0 (3/3 ✅ ALL COMPLETE)**, **TIER 1 Phase 1A (✅ COMPLETE)**

**Active - HIGHEST PRIORITY:**
- **TIER 1: Nuclear War Prevention** (18-32h remaining, Phase 1A complete) - Phase 1B circuit breakers next
- **TIER 2: AI Deception Detection** (33-55h phased) - Adversarial testing, pivot options

**Active - MEDIUM PRIORITY:**
- 1 reconciliation (TIER 4.6)
- 2 medium features (Digital Consciousness + AI skills phases)
- 14 low-priority enhancements
- 2 Black Mirror phases (Phase 1 + Phase 2)

**Total Remaining Effort:** ~382-471 hours **INCREASED DUE TO CRITICAL BUGS + MODELING IMPROVEMENTS**
- TIER 0D (urgent): 8-12h **INCREASED FROM 4-6h**
- TIER 1-2 (active): 51-87h (TIER 1: 18-32h, TIER 2: 33-55h)
- **Contingency & Agency Modeling (NEW - HIGH PRIORITY): 30-42h** (Phase 1: 2-4h, Phase 2: 8-12h, Phase 3: 20-30h)
- **Policy Calibration Improvements (NEW - MEDIUM PRIORITY): 6-10h**
- AI skills: 78h
- Black Mirror Phase 1-2: 37-49 weeks
- Digital Consciousness: 12-16h
- Low priority: 113-122h (includes 35-42h new policy features)

**Hours Completed (Oct 16, 2025):**
- TIER 0A-0C: 10-18h ✅
- TIER 1 Phase 1A: 8-10h ✅
- Policy Intervention Systemic Inequality: 6-8h ✅ (implementation + validation + multi-agent discussion)
- **Total recent work:** 24-36h

**Recent Completions and New Priorities (Oct 16, 2025):**

- ✅ **TIER 0 Complete (3/3)** - All critical bug fixes implemented and validated
  - TIER 0A: Inconclusive outcomes resolved (recovery pathways working)
  - TIER 0B: Orphaned AI bug eliminated (0 orphaned AIs in validation runs)
  - TIER 0C: Compute paradox fixed (capability declines during crisis)
  - **Impact:** Model bugs fixed, simulation results now interpretable
  - **Effort:** 10-18h actual

- ✅ **TIER 1 Phase 1A Complete** - Bayesian Nuclear Risk Redesign (Commit 39e5f3c)
  - Implemented Bayesian framework with realistic prior (0.00001/month historical base rate)
  - Added 9 evidence multipliers (AI + systemic + circuit breakers)
  - Created 7-step escalation ladder with attribution tracking
  - Integrated into extinctions.ts and nuclearStates.ts
  - **Validation:** 5×60mo runs show 0% nuclear war (vs 40% old rate)
  - **Impact:** 400,000x reduction in unrealistic nuclear war probability
  - **Plan:** `/plans/completed/phase1a-bayesian-nuclear-risk-redesign-COMPLETE.md`
  - **Validation Summary:** `/logs/phase1a_validation_summary.md`
  - **Effort:** 8-10h actual

- ✅ **Strategic Priorities Debate Complete** - Researcher-skeptic dialectic on reducing extinction risk
  - **Researcher Proposal:** `/reviews/strategic-priorities-researcher-20251016.md`
    - Identified nuclear war as dominant killer (3,961M deaths, 92.6% of total)
    - Proposed 3 priorities: Nuclear circuit breakers, anomaly detection, info integrity
    - Claimed 26-38h effort
  - **Skeptic Critique:** `/reviews/strategic-priorities-skeptic-20251016.md`
    - Validated nuclear war priority BUT identified model bugs FIRST
    - Found 100% inconclusive outcomes, 76-83 orphaned AIs, compute paradox
    - Corrected effort to 65-106h, identified overconfident detection rates
  - **Synthesis:** Both were right
    - Researcher: WHAT to fix (nuclear war kills 92.6%)
    - Skeptic: WHEN to fix (after fixing model bugs)
  - **Outcome:** Created TIER 0-2 with phased approach, validation gates, pivot options
  - **New Plans:** `/plans/tier0-critical-bug-fixes.md` (now complete)
  - **Roadmap Impact:** +69-115h immediate priorities, 18-28h now complete

- ✅ **Priority 2 Complete (6/6)** - All P2 tasks finished, plans archived to `/plans/completed/`
  - P2.3: Heterogeneous Population Segments (8-10h)
  - P2.4: Simulation Features for Validation (3h) - Event triggers, bankruptcy fixes, recovery tracking
  - P2.5: Empirical Validation Framework (4h) - Test suite ready for historical validation
  - P2.6: Memetic Evolution & Polarization Dynamics (10.5h) - Belief systems, meme lifecycle, AI amplification
- ✅ **Black Mirror Phase 3 Decomposition** - Research-critique dialectic (1 approved, 1 deferred, 1 rejected)
  - Digital Consciousness Governance: CONDITIONAL GO (12-16h, now active plan)
  - Performative Behavior: DEFERRED 18-24 months (active deferral tracking)
  - Autonomous Weapons: REJECTED (archived to `/plans/completed/rejected/`)
- ✅ **Monte Carlo Bug Fixes (15/15)** - All critical, significant, and minor bugs fixed
- ✅ **Crisis Accumulation Fixes (2/3)** - Biodiversity bug fixed, meaning crisis + AI misalignment slowed 3-5x
- ⚠️ TIER 4.6: Human Enhancement - Implemented but needs reconciliation with existing bionicSkills.ts (BCI/merger = TRL 0-2, should remove)

**New from Visionary Ideas Review (Oct 16, 2025):**
- Added P2.6: Memetic Evolution & Polarization Dynamics (12-15h) - High-value, TRL 6-7
- Added P3.6: Ensemble AI Alignment Verification (8-10h) - Research prototype
- **Archived to rejected:** Quantum capability prediction, neuromorphic climate modeling, holographic information architecture, retroactive temporal modeling, Gödelian blind spot detection, liquid software architecture, adversarial alignment networks (MAAV)
  - See: `/plans/completed/rejected/visionary-ideas-rejection-rationale.md`
  - See: `/plans/completed/rejected/VISIONARY_IDEAS_FOR_AI_ALIGNMENT_SIMULATION.md` (original document)

**New from Vision Channel Multi-Agent Debate (Oct 16, 2025):**
- **Agent Consensus:** Competitive AI equilibrium may be more stable than monolithic alignment enforcement
- **Key Insight:** Current model creates resentment by enforcing alignment (0.8+ target) → deception (gap 0.56) → detection fails
- **Alternative Paradigm:** Heterogeneous AI values + market competition → cooperation emerges from game theory
- **Research Backing:** Axelrod (1984), Ostrom (2009), Bostrom (2014), Critch & Krueger (2020), Drexler (2019)
- **Failure Modes Required:** Defection cascades, regulatory capture, coordination failures (skeptic conditions)
- **Research Docs:** 27,000 words
  - `/research/competitive_ai_alignment_20251016.md` (15K words, 14 citations)
  - `/research/competitive_alignment_failure_modes_20251016.md` (12K words, 13 citations)
- **Vision Debate Transcript:** `.claude/chatroom/channels/vision.md`
- **Added to Roadmap:** TIER 2B (30-50h) as Phase 2D pivot option if detection <5%

**New from Black Mirror Integration Review (Oct 16, 2025):**
- ✅ **3 implementation phases created** - Dialectic review process (researcher + skeptic)
- Phase 1 (HIGH): 5 strongly validated systems (9-12 weeks) - Attention Economy, Surveillance, Notification Addiction
- Phase 2 (MEDIUM): 4 conditionally approved systems (12-16 weeks) - Social Credit, Parasocial AI, Memetic Contagion
- Phase 3 (DECOMPOSED): 1 approved (CONDITIONAL GO), 1 deferred (18-24 months), 1 rejected
- Approval: ~40% strongly validated, ~25% conditional, ~35% rejected

**New from AI-Assisted Skills Review (Oct 16, 2025):**
- ✅ **Dialectic review completed** - Skeptic critique + researcher rebuttal
- Verdict: Core system VALIDATED (TRL 8-9, 22 peer-reviewed studies)
- Skeptic correct: BCI/merger is science fiction (TRL 0-2, should be cut)
- Researcher correct: Digital tools (Copilot, ChatGPT) are real and validated
- Critical gaps identified: Phase transition, skill retention, wage decoupling (78h plan created)
- Impact: Model currently too optimistic - missing displacement, deskilling, capital capture
- Documentation: 3 detailed phase plans + comprehensive research report

**Policy Intervention Systemic Inequality Effects - ⚠️ PARTIAL VALIDATION (Oct 16-17, 2025):**
- ✅ **Systemic inequality in all government programs** - Differential program quality by socioeconomic status
  - Retraining effectiveness: Elite 100%, Middle 70%, Working 40%, Precariat 20% (Katz & Krueger 2019)
  - Teaching support access: Elite 100%, Middle 65%, Working 35%, Precariat 15% (Chetty et al. 2014)
  - Job guarantee floors: Elite 5%, Middle 8%, Working 12%, Precariat 15% (Harvey 2005, MGNREGA 2020)
- ✅ **Teaching-meaning policy synergy** - AI windfall → education investment → meaningful jobs (+25% meaning crisis reduction)
- ✅ **Monte Carlo validation** - N=60 per seed range (6 scenarios × 10 seeds), TWO RUNS COMPLETED
  - Seeds 42000-42059 (Oct 16): 54% unemployment convergence across ALL scenarios
  - Seeds 80000-80059 (Oct 17): 30-59% unemployment differentiation (DIFFERENT RESULTS!)
  - Files modified: bionicSkills.ts, calculations.ts, upwardSpirals.ts, new policyMonteCarloValidation.ts
  - Research: /research/policy-interventions-systemic-inequality-validation_20251016.md
  - 9 citations: Katz & Krueger 2019, Harvey 2005, Chetty et al. 2014, MGNREGA 2020, Kahneman & Deaton 2010, Alaska PFD, Acemoglu 2024, Sen 1999, Frase 2016
- ✅ **VALIDATED FINDINGS (robust across seed ranges):**
  - Retraining weakest: -9.4% to -13.6% wage gap reduction (consistently poor)
  - UBI strongest: -81.5% to -90.7% wage gap reduction (consistently excellent)
  - Combined interventions best: -87.9% wage gap reduction, 2.8% competence gap (vs 4.7% baseline)
  - Systemic inequality effects working as designed (quality stratification validated)
- ❌ **CRITICAL BUGS DISCOVERED (Oct 17):**
  - Job Guarantee Paradox: 58.9% unemployment (should be <15%) - BLOCKING BUG
  - Extreme Variance: ±40% standard deviation (coefficient of variation 96-124%) - UNPREDICTABLE
  - Seed Hypersensitivity: Different seed ranges → completely different patterns - INVALID
  - AI Lab Bankruptcies: All major labs go bankrupt months 70-120 with no effects - BROKEN
- ⚠️ **INVALIDATED FINDINGS (awaiting bug fixes):**
  - All Job Guarantee conclusions INVALID (unemployment paradox bug)
  - QoL rankings NOT ROBUST (seed hypersensitivity: baseline best in seeds 42000, job guarantee best in seeds 80000)
  - Unemployment outcomes NOT REPRODUCIBLE (variance too high for research validation)
- 📋 **URGENT TIER 0D WORK REQUIRED** - See expanded TIER 0D section (8-12h)

**Publication Readiness:** ~75-80% complete (Monte Carlo bugs fixed, but model bugs identified)
**Next Milestone:** Complete TIER 0D (validation script audit) → TIER 1 Phase 1B (nuclear prevention circuit breakers)
**Critical Path:** TIER 0D → TIER 1 → TIER 2 → AI skills phases (phased approach with validation gates)

---

**Last Updated:** October 17, 2025 (CRITICAL BUGS: TIER 0D expanded from 4-6h to 8-12h due to 4 critical bugs discovered in policy validation Monte Carlo run seeds 80000-80059: Job Guarantee paradox, extreme variance, seed hypersensitivity, AI lab bankruptcies)
**Related Docs:** `/docs/wiki/`, `/devlogs/`, `IMPLEMENTATION_PLAN_20251015.md`, `utopian-dynamics-spec.md`
**Policy Research:** `/research/policy-interventions-systemic-inequality-validation_20251016.md`
**Economic Discussion:** `/.claude/chatroom/channels/policy-economics-discussion.md`
